"""
Gradioç”¨æˆ·ç•Œé¢
ä¸ªäººçŸ¥è¯†ç®¡ç†åŠ©æ‰‹çš„Webç•Œé¢
"""

import os
import logging
import gradio as gr
from typing import List, Optional, Dict, Any
from pathlib import Path
from langchain_core.messages import SystemMessage, HumanMessage

from config.settings import settings
from src.ingestion.document_loader_simple import DocumentLoader, DocumentClassifier
from src.storage.vector_store_simple import VectorStore, HybridRetriever
from src.generation.llm_manager import LLMManager, RAGGenerator, ModelRouter
from src.utils.search_history import SearchHistoryManager

# è·å–æ—¥å¿—å™¨ï¼ˆæ—¥å¿—å·²åœ¨main.pyä¸­ç»Ÿä¸€é…ç½®ï¼‰
logger = logging.getLogger(__name__)

class KnowledgeManagerApp:
    """çŸ¥è¯†ç®¡ç†åº”ç”¨ä¸»ç±»"""

    def __init__(self):
        # åˆå§‹åŒ–ç»„ä»¶
        self.document_loader = DocumentLoader()
        self.document_classifier = DocumentClassifier()
        self.vector_store = VectorStore()
        self.hybrid_retriever = HybridRetriever(self.vector_store)
        # æ™ºèƒ½åˆå§‹åŒ–LLMç»„ä»¶
        self.llm_manager = None
        self.rag_generator = None
        self.model_router = None
        self.llm_enabled = False

        # å°è¯•åˆå§‹åŒ–LLMç»„ä»¶
        try:
            self.llm_manager = LLMManager()
            if self.llm_manager.chat_model:  # åªæœ‰åœ¨æœ‰DeepSeek APIçš„æƒ…å†µä¸‹æ‰å¯ç”¨å®Œæ•´åŠŸèƒ½
                self.rag_generator = RAGGenerator(self.llm_manager)
                self.model_router = ModelRouter()
                self.llm_enabled = True
                logger.info("âœ… LLMåŠŸèƒ½å·²å¯ç”¨")
            else:
                logger.info("â„¹ï¸ DeepSeek APIæœªé…ç½®ï¼Œä½¿ç”¨ç®€åŒ–å›ç­”æ¨¡å¼")
        except Exception as e:
            logger.warning(f"LLMåŠŸèƒ½åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€åŒ–æ¨¡å¼: {e}")

        # æœç´¢å†å²ç®¡ç†å™¨
        self.search_history_manager = SearchHistoryManager()

        # çŠ¶æ€ç®¡ç†
        self.conversation_history = []
        self.current_session_id = None

        # éªŒè¯é…ç½®
        settings.validate()

        logger.info("çŸ¥è¯†ç®¡ç†åº”ç”¨åˆå§‹åŒ–å®Œæˆ")

    def load_and_process_files(self, files: List[str], progress=gr.Progress()) -> str:
        """
        åŠ è½½å’Œå¤„ç†ä¸Šä¼ çš„æ–‡ä»¶

        Args:
            files: ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            progress: Gradioè¿›åº¦è·Ÿè¸ªå™¨

        Returns:
            å¤„ç†ç»“æœæ¶ˆæ¯
        """
        from src.utils.recovery import RecoveryManager
        import os
        
        # åˆå§‹åŒ–æ¢å¤ç®¡ç†å™¨
        recovery_manager = RecoveryManager()
        
        try:
            if not files:
                return "è¯·é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶ã€‚"

            # æ–‡ä»¶å¤§å°é™åˆ¶ (50MB)
            MAX_FILE_SIZE = 50 * 1024 * 1024
            
            # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
            SUPPORTED_EXTENSIONS = {'.txt', '.md', '.pdf', '.doc', '.docx'}

            logger.info(f"å¼€å§‹å¤„ç† {len(files)} ä¸ªæ–‡ä»¶")
            progress(0, desc="å¼€å§‹å¤„ç†æ–‡ä»¶...")

            # æ‰¹é‡å¤„ç†æ–‡ä»¶
            all_documents = []
            processed_files = []
            skipped_files = []
            updated_files = []
            failed_files = []
            
            total_files = len(files)
            for idx, file_path in enumerate(files):
                try:
                    # æ›´æ–°è¿›åº¦
                    current_progress = idx / total_files
                    file_name = Path(file_path).name
                    progress(current_progress, desc=f"å¤„ç†æ–‡ä»¶ {idx+1}/{total_files}: {file_name}")
                    
                    # ä¿å­˜å“ˆå¸Œå€¼å˜é‡
                    new_content_hash = None
                    
                    # === æ–‡ä»¶éªŒè¯ ===
                    # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    if not os.path.exists(file_path):
                        logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_name}")
                        failed_files.append((file_name, "æ–‡ä»¶ä¸å­˜åœ¨"))
                        continue
                    
                    # 2. æ£€æŸ¥æ–‡ä»¶ç±»å‹
                    file_ext = Path(file_path).suffix.lower()
                    if file_ext not in SUPPORTED_EXTENSIONS:
                        logger.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ {file_ext}: {file_name}")
                        failed_files.append((file_name, f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ {file_ext}"))
                        continue
                    
                    # 3. æ£€æŸ¥æ–‡ä»¶å¤§å°
                    try:
                        file_size = os.path.getsize(file_path)
                        if file_size > MAX_FILE_SIZE:
                            size_mb = file_size / (1024 * 1024)
                            logger.warning(f"æ–‡ä»¶è¿‡å¤§ ({size_mb:.1f}MB): {file_name}")
                            failed_files.append((file_name, f"æ–‡ä»¶è¿‡å¤§ ({size_mb:.1f}MBï¼Œé™åˆ¶50MB)"))
                            continue
                        if file_size == 0:
                            logger.warning(f"æ–‡ä»¶ä¸ºç©º: {file_name}")
                            failed_files.append((file_name, "æ–‡ä»¶ä¸ºç©º"))
                            continue
                    except OSError as e:
                        logger.error(f"æ— æ³•è¯»å–æ–‡ä»¶å¤§å° {file_name}: {str(e)}")
                        failed_files.append((file_name, "æ— æ³•è¯»å–æ–‡ä»¶å¤§å°"))
                        continue
                    
                    # 4. æ£€æŸ¥æ–‡ä»¶è¯»å–æƒé™
                    if not os.access(file_path, os.R_OK):
                        logger.warning(f"æ²¡æœ‰æ–‡ä»¶è¯»å–æƒé™: {file_name}")
                        failed_files.append((file_name, "æ²¡æœ‰è¯»å–æƒé™"))
                        continue
                    
                    # === ä¿å­˜å¤„ç†æ£€æŸ¥ç‚¹ ===
                    recovery_manager.save_checkpoint('file_upload', {
                        'file_name': file_name,
                        'file_path': file_path,
                        'stage': 'validation_passed'
                    })
                    
                    # è®¡ç®—æ–°æ–‡ä»¶å†…å®¹å“ˆå¸Œï¼ˆç»Ÿä¸€åœ¨æ­¤å¤„è®¡ç®—ï¼‰
                    try:
                        with open(file_path, 'rb') as f:
                            import hashlib
                            new_content_hash = hashlib.md5(f.read()).hexdigest()
                    except PermissionError:
                        logger.error(f"è¯»å–æ–‡ä»¶æƒé™è¢«æ‹’ç»: {file_name}")
                        failed_files.append((file_name, "è¯»å–æƒé™è¢«æ‹’ç»"))
                        continue
                    except IOError as e:
                        logger.error(f"æ–‡ä»¶è¯»å–é”™è¯¯ {file_name}: {str(e)}")
                        failed_files.append((file_name, f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}"))
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒåæ–‡æ¡£
                    existing_docs = self.vector_store.collection.get()
                    file_exists = False
                    if existing_docs['metadatas']:
                        for metadata in existing_docs['metadatas']:
                            if metadata.get('filename') == file_name:
                                file_exists = True
                                break
                    
                    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ¤æ–­æ˜¯å¦ç›¸åŒ
                    if file_exists:
                        # è·å–æ—§æ–‡ä»¶çš„å“ˆå¸Œï¼ˆä»è¯¥æ–‡ä»¶çš„ä»»æ„ä¸€ä¸ªå—çš„metadataä¸­è¯»å–file_hashï¼‰
                        old_file_hash = None
                        for metadata in existing_docs['metadatas']:
                            if metadata.get('filename') == file_name:
                                # ä»metadataä¸­è¯»å–æ–‡ä»¶çº§åˆ«çš„hash
                                old_file_hash = metadata.get('file_hash')
                                break
                        
                        # æ¯”è¾ƒå“ˆå¸Œå€¼
                        if new_content_hash == old_file_hash:
                            # å†…å®¹å®Œå…¨ç›¸åŒï¼Œè·³è¿‡å¤„ç†
                            logger.info(f"æ–‡ä»¶å†…å®¹æœªå˜åŒ–ï¼Œè·³è¿‡: {file_name}")
                            skipped_files.append(file_name)
                            continue
                        else:
                            # å†…å®¹ä¸åŒï¼Œåˆ é™¤æ—§ç‰ˆæœ¬ï¼Œæ·»åŠ æ–°ç‰ˆæœ¬
                            logger.info(f"æ£€æµ‹åˆ°æ–‡ä»¶å†…å®¹å˜åŒ–ï¼Œæ›´æ–°: {file_name}")
                            self.vector_store.delete_documents({"filename": file_name})
                            updated_files.append(file_name)
                    
                    # === åŠ è½½æ–‡æ¡£ ===
                    recovery_manager.save_checkpoint('file_upload', {
                        'file_name': file_name,
                        'stage': 'loading_document'
                    })
                    
                    progress(current_progress + 0.3/total_files, desc=f"åŠ è½½æ–‡æ¡£: {file_name}")
                    documents = self.document_loader.load_file(file_path)

                    # ä¸ºæ¯ä¸ªæ–‡æ¡£æ·»åŠ åˆ†ç±»ä¿¡æ¯å’Œæ–‡ä»¶å“ˆå¸Œ
                    progress(current_progress + 0.5/total_files, desc=f"åˆ†ç±»æ–‡æ¡£: {file_name}")
                    import time
                    upload_timestamp = time.time()  # è·å–ä¸Šä¼ æ—¶é—´æˆ³
                    
                    for doc in documents:
                        classification = self.document_classifier.classify_document(doc)
                        # æ¸…ç†Noneå€¼ï¼ˆChromaDBä¸æ¥å—Noneç±»å‹çš„metadataï¼‰
                        classification = {k: v for k, v in classification.items() if v is not None}
                        doc.metadata.update(classification)
                        # æ·»åŠ æ–‡ä»¶çº§åˆ«çš„hashåˆ°æ¯ä¸ªchunk
                        doc.metadata['file_hash'] = new_content_hash
                        # æ·»åŠ ä¸Šä¼ æ—¶é—´æˆ³
                        doc.metadata['upload_time'] = upload_timestamp

                    all_documents.extend(documents)
                    processed_files.append(file_name)
                    
                    # æ¸…é™¤æˆåŠŸçš„æ£€æŸ¥ç‚¹
                    recovery_manager.clear_checkpoint()

                except PermissionError as e:
                    logger.error(f"æ–‡ä»¶æƒé™é”™è¯¯ {file_path}: {str(e)}")
                    failed_files.append((Path(file_path).name, "æƒé™ä¸è¶³"))
                    continue
                except IOError as e:
                    logger.error(f"æ–‡ä»¶IOé”™è¯¯ {file_path}: {str(e)}")
                    failed_files.append((Path(file_path).name, f"IOé”™è¯¯: {str(e)}"))
                    continue
                except Exception as e:
                    logger.warning(f"æ–‡ä»¶å¤„ç†å¤±è´¥ {file_path}: {str(e)}")
                    failed_files.append((Path(file_path).name, str(e)))
                    continue

            # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
            if all_documents:
                progress(0.9, desc=f"ç”ŸæˆEmbedding ({len(all_documents)} ä¸ªæ–‡æ¡£å—)...")
                success = self.vector_store.add_documents(all_documents)
                if success:
                    progress(1.0, desc="å¤„ç†å®Œæˆ!")
                    result = f"âœ… æˆåŠŸå¤„ç† {len(all_documents)} ä¸ªæ–‡æ¡£å—\n\n"
                    
                    # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
                    if processed_files:
                        result += f"ğŸ“„ **æ–°å¢æ–‡ä»¶**: {len(processed_files)} ä¸ª\n"
                        for fname in processed_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                            result += f"  â€¢ {fname}\n"
                        if len(processed_files) > 5:
                            result += f"  â€¢ ... è¿˜æœ‰ {len(processed_files)-5} ä¸ª\n"
                    
                    if updated_files:
                        result += f"\nğŸ”„ **æ›´æ–°æ–‡ä»¶**: {len(updated_files)} ä¸ªï¼ˆå†…å®¹å·²å˜åŒ–ï¼‰\n"
                        for fname in updated_files:
                            result += f"  â€¢ {fname}\n"
                    
                    if skipped_files:
                        result += f"\nâ­ï¸ **è·³è¿‡æ–‡ä»¶**: {len(skipped_files)} ä¸ªï¼ˆå†…å®¹æœªå˜åŒ–ï¼‰\n"
                        for fname in skipped_files:
                            result += f"  â€¢ {fname}\n"
                    
                    if failed_files:
                        result += f"\nâŒ **å¤±è´¥æ–‡ä»¶**: {len(failed_files)} ä¸ª\n"
                        for fname, reason in failed_files:
                            result += f"  â€¢ {fname}: {reason}\n"
                    
                    result += f"\nğŸ“Š **æ–‡æ¡£åˆ†ç±»ç»Ÿè®¡**ï¼š\n"

                    # ç»Ÿè®¡åˆ†ç±»ä¿¡æ¯
                    categories = {}
                    for doc in all_documents:
                        category = doc.metadata.get('category', 'æœªçŸ¥')
                        categories[category] = categories.get(category, 0) + 1

                    for category, count in categories.items():
                        category_desc = {
                            "å·¥ä½œ": "ä¸å·¥ä½œç›¸å…³çš„æ–‡æ¡£å†…å®¹",
                            "å­¦ä¹ ": "å­¦ä¹ ç¬”è®°æˆ–æ•™ç¨‹",
                            "ç ”ç©¶": "ç ”ç©¶æˆ–å­¦æœ¯ç›¸å…³çš„å†…å®¹",
                            "å‚è€ƒ": "å‚è€ƒèµ„æ–™æˆ–å¼•ç”¨å†…å®¹",
                            "æƒ³æ³•": "ä¸ªäººè§è§£æˆ–åˆ›æ„æƒ³æ³•",
                            "ä¸ªäºº": "ä¸ªäººæ—¥å¸¸æˆ–ç”Ÿæ´»è®°å½•",
                            "æœªçŸ¥": "æœªåˆ†ç±»çš„å†…å®¹"
                        }.get(category, "å…¶ä»–åˆ†ç±»å†…å®¹")

                        result += f"  â€¢ {category}: {count} ä¸ªå— ({category_desc})\n"

                    result += f"\nğŸ’¡ è¿™äº›æ–‡æ¡£å—ç°åœ¨å·²ç»å­˜å‚¨åœ¨çŸ¥è¯†åº“ä¸­ï¼Œå¯ä»¥é€šè¿‡æ™ºèƒ½é—®ç­”åŠŸèƒ½è¿›è¡ŒæŸ¥è¯¢å’Œå¯¹è¯ã€‚"
                    return result
                else:
                    return "âŒ æ–‡ä»¶å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚"
            elif skipped_files or failed_files:
                # åªæœ‰è·³è¿‡å’Œå¤±è´¥çš„æƒ…å†µ
                result = ""
                if skipped_files:
                    result += f"â­ï¸ **è·³è¿‡æ–‡ä»¶**: {len(skipped_files)} ä¸ªï¼ˆå†…å®¹æœªå˜åŒ–ï¼‰\n"
                    for fname in skipped_files:
                        result += f"  â€¢ {fname}\n"
                if failed_files:
                    if skipped_files:
                        result += "\n"
                    result += f"âŒ **å¤±è´¥æ–‡ä»¶**: {len(failed_files)} ä¸ª\n"
                    for fname, reason in failed_files:
                        result += f"  â€¢ {fname}: {reason}\n"
                return result if result else "âš ï¸ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶ã€‚"
            else:
                return "âš ï¸ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶ã€‚"

        except Exception as e:
            logger.error(f"æ–‡ä»¶å¤„ç†å¼‚å¸¸: {str(e)}")
            # å°è¯•æ¢å¤ä¸Šæ¬¡çš„æ£€æŸ¥ç‚¹
            checkpoint = recovery_manager.load_last_checkpoint()
            if checkpoint:
                logger.info(f"æ£€æµ‹åˆ°æ£€æŸ¥ç‚¹: {checkpoint}")
                return f"âŒ å¤„ç†å¤±è´¥: {str(e)}\nğŸ’¡ ä¸Šæ¬¡å¤„ç†åˆ°: {checkpoint.get('file_name', 'æœªçŸ¥')} - {checkpoint.get('stage', 'æœªçŸ¥é˜¶æ®µ')}"
            return f"âŒ å¤„ç†å¤±è´¥: {str(e)}"

    def chat_with_knowledge(self, message: str, history: List[Dict[str, str]]) -> str:
        """
        åŸºäºçŸ¥è¯†åº“çš„å¯¹è¯ï¼ˆæ™ºèƒ½æ¨¡å¼ï¼šLLMä¼˜å…ˆï¼Œç®€åŒ–æ¨¡å¼å¤‡ç”¨ï¼‰

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            history: å¯¹è¯å†å²

        Returns:
            AIå›ç­”
        """
        try:
            if not message.strip():
                return "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ã€‚"

            logger.info(f"æ”¶åˆ°ç”¨æˆ·é—®é¢˜: {message[:50]}..., å†å²è½®æ•°: {len(history)//2 if history else 0}")

            # æ„å»ºä¸Šä¸‹æ–‡æŸ¥è¯¢ï¼ˆç»“åˆæœ€è¿‘3è½®å¯¹è¯ï¼‰
            context_query = message
            if history and len(history) >= 2:
                # è·å–æœ€è¿‘3è½®å¯¹è¯ï¼ˆ6æ¡æ¶ˆæ¯ï¼‰
                recent_history = history[-6:] if len(history) > 6 else history
                context_parts = []
                for msg in recent_history:
                    if msg['role'] == 'user':
                        context_parts.append(f"ç”¨æˆ·: {msg['content']}")
                    elif msg['role'] == 'assistant':
                        # åªä¿ç•™ç®€çŸ­æ‘˜è¦ï¼Œä¸åŒ…å«å®Œæ•´å›ç­”
                        content = msg['content'][:100] if len(msg['content']) > 100 else msg['content']
                        context_parts.append(f"åŠ©æ‰‹: {content}")
                
                # ç»„åˆæŸ¥è¯¢ï¼ˆå½“å‰é—®é¢˜ + ä¸Šä¸‹æ–‡ï¼‰
                context_query = f"{' '.join(context_parts[-2:])} {message}"
                logger.info(f"ä½¿ç”¨ä¸Šä¸‹æ–‡æŸ¥è¯¢: {context_query[:100]}...")

            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            retrieved_docs = self.vector_store.search(context_query, k=settings.TOP_K)

            if not retrieved_docs:
                return "æˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚è¯·å°è¯•ï¼š\n1. æ£€æŸ¥é—®é¢˜è¡¨è¿°\n2. ä¸Šä¼ ç›¸å…³æ–‡æ¡£\n3. ä½¿ç”¨ä¸åŒçš„å…³é”®è¯"

            # å¦‚æœLLMåŠŸèƒ½å¯ç”¨ä¸”æœ‰DeepSeek APIï¼Œä½¿ç”¨RAGç”Ÿæˆå™¨
            if self.llm_enabled and self.rag_generator:
                try:
                    # æ„å»ºå¯¹è¯å†å²ï¼ˆä¼ é€’ç»™LLMï¼‰
                    conversation_context = []
                    if history:
                        # åªä¿ç•™æœ€è¿‘5è½®å¯¹è¯
                        recent = history[-10:] if len(history) > 10 else history
                        for msg in recent:
                            conversation_context.append({
                                'role': msg['role'],
                                'content': msg['content'][:500]  # é™åˆ¶é•¿åº¦
                            })
                    
                    # ä½¿ç”¨RAGç”Ÿæˆå™¨ç”Ÿæˆæ™ºèƒ½å›ç­”ï¼ˆä¼ é€’å¯¹è¯å†å²ï¼‰
                    result = self.rag_generator.generate_answer(
                        query=message,
                        documents=retrieved_docs,
                        include_sources=True,
                        conversation_history=conversation_context  # ä¼ é€’ä¸Šä¸‹æ–‡
                    )

                    # æ„å»ºå›ç­”
                    answer_parts = []
                    answer_parts.append("ğŸ¤– **AI æ™ºèƒ½å›ç­”ï¼š**\n")
                    answer_parts.append(f"{result['answer']}\n")

                    # æ·»åŠ ç½®ä¿¡åº¦ä¿¡æ¯
                    if result['confidence'] > 0:
                        confidence_level = "é«˜" if result['confidence'] > 0.8 else "ä¸­" if result['confidence'] > 0.5 else "ä½"
                        answer_parts.append(f"\nğŸ“Š ç½®ä¿¡åº¦ï¼š{confidence_level} ({result['confidence']:.2f})")

                    # æ·»åŠ æ¥æºä¿¡æ¯ï¼ˆå¸¦å¼•ç”¨ç¼–å·ï¼‰
                    if result['sources']:
                        answer_parts.append("\n\nğŸ“š **å¼•ç”¨æ¥æºï¼š**\n")
                        for i, source in enumerate(result['sources'][:3], 1):
                            filename = source['filename']
                            relevance = source['relevance_score']
                            chunk_id = source.get('chunk_id', '?')
                            # æ·»åŠ å¯ç‚¹å‡»çš„å¼•ç”¨æ ¼å¼
                            answer_parts.append(f"[{i}] ğŸ“„ **{filename}** (chunk {chunk_id}, ç›¸å…³æ€§: {relevance:.2f})\n")
                            # æ˜¾ç¤ºå¼•ç”¨å†…å®¹ç‰‡æ®µ
                            if 'content' in source:
                                preview = source['content'][:150] if len(source['content']) > 150 else source['content']
                                answer_parts.append(f"   _{preview}..._\n\n")

                    # æ·»åŠ tokenä½¿ç”¨é‡
                    if result['metadata']['tokens_used']:
                        answer_parts.append(f"\nğŸ’¬ Tokenä½¿ç”¨é‡ï¼š{result['metadata']['tokens_used']}")
                    
                    # ç”Ÿæˆç›¸å…³é—®é¢˜æ¨è
                    try:
                        suggested_questions = self._generate_suggested_questions(message, result['answer'], retrieved_docs)
                        if suggested_questions:
                            answer_parts.append("\n\nğŸ’¡ **æ‚¨å¯èƒ½è¿˜æƒ³äº†è§£ï¼š**\n")
                            for i, q in enumerate(suggested_questions, 1):
                                answer_parts.append(f"{i}. {q}\n")
                    except Exception as sq_error:
                        logger.warning(f"æ¨èé—®é¢˜ç”Ÿæˆå¤±è´¥: {sq_error}")

                    answer = "".join(answer_parts)

                    logger.info(f"AI å›ç­”ç”Ÿæˆå®Œæˆ: æŸ¥è¯¢='{message[:30]}...', ç½®ä¿¡åº¦={result['confidence']:.2f}, ä½¿ç”¨ä¸Šä¸‹æ–‡={len(conversation_context)}æ¡")
                    return answer

                except Exception as e:
                    logger.warning(f"RAGç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°ç®€åŒ–æ¨¡å¼: {e}")
                    # å›é€€åˆ°ç®€åŒ–æ¨¡å¼
                    # å›é€€åˆ°ç®€åŒ–æ¨¡å¼

            # ç®€åŒ–æ¨¡å¼å›ç­”ï¼ˆä¸ä¾èµ–LLMï¼‰
            answer_parts = []
            answer_parts.append("ğŸ” **åŸºäºçŸ¥è¯†åº“çš„å›ç­”ï¼š**\n")

            # æ·»åŠ æœ€ç›¸å…³çš„æ–‡æ¡£å†…å®¹
            for i, doc in enumerate(retrieved_docs[:3], 1):
                filename = doc.metadata.get('filename', 'æœªçŸ¥æ–‡ä»¶')
                relevance = doc.metadata.get('relevance_score', 0.0)
                content = doc.page_content

                # æˆªå–æœ€ç›¸å…³çš„éƒ¨åˆ†
                if len(content) > 300:
                    content = content[:300] + "..."

                answer_parts.append(f"**{i}. {filename}** (ç›¸å…³æ€§: {relevance:.2f})\n")
                answer_parts.append(f"{content}\n")

            # æ·»åŠ æ¥æºä¿¡æ¯
            answer_parts.append("\nğŸ“š **ç›¸å…³æ–‡æ¡£æ¥æºï¼š**\n")
            for i, doc in enumerate(retrieved_docs[:3], 1):
                filename = doc.metadata.get('filename', 'æœªçŸ¥æ–‡ä»¶')
                answer_parts.append(f"{i}. {filename}\n")

            answer_parts.append(f"\nğŸ’¡ *æç¤ºï¼šæ‰¾åˆ° {len(retrieved_docs)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ*")

            # å¦‚æœæœ‰embeddingä¿¡æ¯ï¼Œæ·»åŠ embeddingæ–¹æ³•ä¿¡æ¯
            if hasattr(self, 'vector_store') and hasattr(self.vector_store, 'embedding_manager'):
                method_info = self.vector_store.embedding_manager.get_method_info()
                answer_parts.append(f"\nğŸ”§ *Embeddingæ–¹æ³•ï¼š{method_info['description']}*")

            answer = "".join(answer_parts)

            logger.info(f"æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(retrieved_docs)} ä¸ªç›¸å…³æ–‡æ¡£")
            return answer

        except Exception as e:
            logger.error(f"å¯¹è¯ç”Ÿæˆå¤±è´¥: {str(e)}")
            return f"æŠ±æ­‰ï¼Œå›ç­”ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}"
    
    def _generate_suggested_questions(self, original_query: str, answer: str, documents: List) -> List[str]:
        """
        åŸºäºå½“å‰é—®é¢˜å’Œç­”æ¡ˆç”Ÿæˆç›¸å…³é—®é¢˜æ¨è
        
        Args:
            original_query: åŸå§‹é—®é¢˜
            answer: AIå›ç­”
            documents: æ£€ç´¢åˆ°çš„æ–‡æ¡£
            
        Returns:
            æ¨èé—®é¢˜åˆ—è¡¨ï¼ˆ3-5ä¸ªï¼‰
        """
        try:
            if not self.llm_enabled or not self.llm_manager:
                # æ²¡æœ‰LLMï¼Œä½¿ç”¨ç®€å•çš„åŸºäºå…³é”®è¯çš„æ¨è
                return self._generate_simple_suggestions(documents)
            
            # ä½¿ç”¨LLMç”Ÿæˆæ¨èé—®é¢˜
            prompt = f"""åŸºäºä»¥ä¸‹å¯¹è¯ï¼Œç”Ÿæˆ3-5ä¸ªç”¨æˆ·å¯èƒ½æ„Ÿå…´è¶£çš„åç»­é—®é¢˜ã€‚

åŸå§‹é—®é¢˜: {original_query}
å›ç­”: {answer[:300]}...

è¯·ç”Ÿæˆç®€æ´ã€å…·ä½“çš„åç»­é—®é¢˜ï¼Œæ¯è¡Œä¸€ä¸ªé—®é¢˜ï¼Œä¸è¦ç¼–å·ã€‚ç›´æ¥è¾“å‡ºé—®é¢˜å³å¯ã€‚"""
            
            messages = [
                SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·å‘ç°ç›¸å…³é—®é¢˜ã€‚"),
                HumanMessage(content=prompt)
            ]
            
            response = self.llm_manager.chat_model.invoke(messages)
            suggestions_text = response.content if hasattr(response, 'content') else str(response)
            
            # è§£æå»ºè®®é—®é¢˜
            suggestions = []
            for line in suggestions_text.strip().split('\n'):
                line = line.strip()
                # ç§»é™¤ç¼–å·ï¼ˆå¦‚ "1. "ï¼‰
                line = line.lstrip('0123456789.ã€- ')
                if line and len(line) > 5:  # è¿‡æ»¤å¤ªçŸ­çš„è¡Œ
                    suggestions.append(line)
            
            return suggestions[:5]  # æœ€å¤šè¿”å›5ä¸ª
            
        except Exception as e:
            logger.warning(f"æ¨èé—®é¢˜ç”Ÿæˆå¤±è´¥: {e}")
            return self._generate_simple_suggestions(documents)
    
    def _generate_simple_suggestions(self, documents: List) -> List[str]:
        """
        åŸºäºæ–‡æ¡£å†…å®¹ç”Ÿæˆç®€å•çš„é—®é¢˜æ¨èï¼ˆä¸ä½¿ç”¨LLMï¼‰
        
        Args:
            documents: æ£€ç´¢åˆ°çš„æ–‡æ¡£
            
        Returns:
            æ¨èé—®é¢˜åˆ—è¡¨
        """
        suggestions = []
        categories = set()
        filenames = set()
        
        # æ”¶é›†æ–‡æ¡£ä¿¡æ¯
        for doc in documents[:3]:
            if 'category' in doc.metadata:
                categories.add(doc.metadata['category'])
            if 'filename' in doc.metadata:
                filenames.add(doc.metadata['filename'])
        
        # ç”ŸæˆåŸºäºåˆ†ç±»çš„é—®é¢˜
        if categories:
            cat = list(categories)[0]
            suggestions.append(f"è¿˜æœ‰å“ªäº›å…³äº{cat}çš„å†…å®¹ï¼Ÿ")
        
        # ç”ŸæˆåŸºäºæ–‡ä»¶çš„é—®é¢˜
        if len(filenames) > 1:
            suggestions.append(f"è¿™äº›æ–‡æ¡£ä¹‹é—´æœ‰ä»€ä¹ˆè”ç³»ï¼Ÿ")
        
        # é€šç”¨é—®é¢˜
        suggestions.append("èƒ½å¦æä¾›æ›´è¯¦ç»†çš„è¯´æ˜ï¼Ÿ")
        suggestions.append("æœ‰ç›¸å…³çš„ç¤ºä¾‹å—ï¼Ÿ")
        
        return suggestions[:3]

    def search_knowledge(self, query: str, mode: str = "æ··åˆæ£€ç´¢", top_k: int = 5, progress=gr.Progress()) -> str:
        """
        æœç´¢çŸ¥è¯†åº“

        Args:
            query: æœç´¢æŸ¥è¯¢
            mode: æœç´¢æ¨¡å¼
            top_k: è¿”å›ç»“æœæ•°é‡
            progress: Gradioè¿›åº¦è·Ÿè¸ªå™¨

        Returns:
            æœç´¢ç»“æœ
        """
        try:
            if not query.strip():
                return "âš ï¸ è¯·è¾“å…¥æœç´¢å…³é”®è¯ã€‚"

            logger.info(f"[æœç´¢] å¼€å§‹æœç´¢: query='{query}', mode='{mode}', top_k={top_k}")
            progress(0, desc="æ­£åœ¨æœç´¢...")

            # æ ¹æ®æ¨¡å¼é€‰æ‹©æ£€ç´¢æ–¹æ³•
            if mode == "æ··åˆæ£€ç´¢":
                progress(0.3, desc="æ‰§è¡Œæ··åˆæ£€ç´¢...")
                documents = self.hybrid_retriever.hybrid_search(query, k=top_k)
                logger.info(f"[æœç´¢] æ··åˆæ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ°{len(documents)}ä¸ªç»“æœ")
            else:
                progress(0.3, desc="æ‰§è¡Œè¯­ä¹‰æ£€ç´¢...")
                documents = self.vector_store.search(query, k=top_k)
                logger.info(f"[æœç´¢] è¯­ä¹‰æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ°{len(documents)}ä¸ªç»“æœ")

            progress(0.7, desc="è®°å½•æœç´¢å†å²...")
            # è®°å½•æœç´¢å†å²
            self.search_history_manager.add_search(
                query=query,
                mode=mode,
                top_k=top_k,
                results_count=len(documents)
            )

            if not documents:
                progress(1.0, desc="æœç´¢å®Œæˆ")
                return f"âŒ æœªæ‰¾åˆ°ä¸ '{query}' ç›¸å…³çš„æ–‡æ¡£ã€‚\n\nğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿å·²ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“ã€‚"

            progress(0.9, desc="æ ¼å¼åŒ–ç»“æœ...")
            # æ„å»ºæœç´¢ç»“æœ
            result = f"ğŸ” **æœç´¢ç»“æœ** (å…±æ‰¾åˆ° {len(documents)} ä¸ªç›¸å…³æ–‡æ¡£å—):\n\n"

            for i, doc in enumerate(documents, 1):
                filename = doc.metadata.get('filename', 'æœªçŸ¥æ–‡ä»¶')
                category = doc.metadata.get('category', 'æœªåˆ†ç±»')
                chunk_id = doc.metadata.get('chunk_id', 0)
                total_chunks = doc.metadata.get('total_chunks', '?')
                relevance = doc.metadata.get('relevance_score', 0.0)
                
                content_preview = doc.page_content[:200].strip()
                if len(doc.page_content) > 200:
                    content_preview += "..."

                result += f"**{i}. {filename}** (ç¬¬{chunk_id + 1}/{total_chunks}å— | {category})\n"
                result += f"   ğŸ“Š ç›¸å…³æ€§: {relevance:.2f}\n"
                result += f"   ğŸ“ å†…å®¹é¢„è§ˆ: {content_preview}\n\n"

            result += f"\nğŸ’¡ *æœç´¢æ¨¡å¼: {mode} | è¿”å›{len(documents)}ä¸ªç»“æœ*"

            progress(1.0, desc="æœç´¢å®Œæˆ!")
            logger.info(f"[æœç´¢] è¿”å›æ ¼å¼åŒ–ç»“æœï¼Œé•¿åº¦={len(result)}")
            return result

        except Exception as e:
            logger.error(f"[æœç´¢] æœç´¢å¤±è´¥: {str(e)}", exc_info=True)
            return f"âŒ æœç´¢å¤±è´¥: {str(e)}\n\nğŸ’¡ æç¤ºï¼šè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†ä¿¡æ¯ã€‚"

    def get_document_list(self) -> list:
        """
        è·å–æ‰€æœ‰æ–‡æ¡£åˆ—è¡¨
        
        Returns:
            æ–‡æ¡£åˆ—è¡¨ [[filename, chunks, category, file_type, file_size, last_updated], ...]
        """
        try:
            from datetime import datetime
            import time
            
            # ä»collectionè·å–æ‰€æœ‰metadataå’ŒIDs
            all_docs = self.vector_store.collection.get(include=['metadatas'])
            
            # æŒ‰æ–‡ä»¶ååˆ†ç»„ç»Ÿè®¡
            file_stats = {}
            for i, metadata in enumerate(all_docs['metadatas']):
                filename = metadata.get('filename', 'æœªçŸ¥')
                if filename not in file_stats:
                    # è·å–ä¸Šä¼ æ—¶é—´ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨Noneæ ‡è®°ä¸ºæ—§æ–‡æ¡£
                    upload_time = metadata.get('upload_time')
                    
                    file_stats[filename] = {
                        'filename': filename,
                        'chunks': 0,
                        'category': metadata.get('category', 'æœªåˆ†ç±»'),
                        'file_type': metadata.get('file_type', 'æœªçŸ¥'),
                        'file_size': metadata.get('file_size', 0),
                        'upload_time': upload_time  # ä»metadataè¯»å–ï¼Œå¯èƒ½ä¸ºNone
                    }
                file_stats[filename]['chunks'] += 1
            
            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
            result = []
            for f in file_stats.values():
                # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
                size_mb = f['file_size']
                if size_mb < 0.01:
                    size_str = f"{size_mb * 1024:.1f} KB"
                else:
                    size_str = f"{size_mb:.2f} MB"
                
                # æ ¼å¼åŒ–ä¸Šä¼ æ—¶é—´
                if f['upload_time'] is not None:
                    # æœ‰æ—¶é—´æˆ³ï¼Œæ ¼å¼åŒ–æ˜¾ç¤º
                    last_updated = datetime.fromtimestamp(f['upload_time']).strftime('%Y-%m-%d %H:%M')
                else:
                    # æ—§æ–‡æ¡£ï¼Œæ˜¾ç¤º"æœªè®°å½•"
                    last_updated = "æœªè®°å½•"
                
                result.append([
                    f['filename'], 
                    f['chunks'], 
                    f['category'], 
                    f['file_type'],
                    size_str,
                    last_updated
                ])
            
            logger.info(f"è·å–æ–‡æ¡£åˆ—è¡¨æˆåŠŸï¼Œå…±{len(result)}ä¸ªæ–‡ä»¶")
            return result
            
        except Exception as e:
            logger.error(f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []
    
    def preview_document(self, filename: str, preview_chunks: int = 3) -> str:
        """
        é¢„è§ˆæ–‡æ¡£å†…å®¹
        
        Args:
            filename: æ–‡ä»¶å
            preview_chunks: é¢„è§ˆçš„chunkæ•°é‡ï¼ˆé»˜è®¤3ä¸ªï¼‰
            
        Returns:
            é¢„è§ˆå†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰
        """
        try:
            if not filename or not filename.strip():
                return "âš ï¸ è¯·è¾“å…¥è¦é¢„è§ˆçš„æ–‡ä»¶å"
            
            logger.info(f"é¢„è§ˆæ–‡æ¡£: {filename}")
            
            # è·å–è¯¥æ–‡ä»¶çš„æ‰€æœ‰chunks
            all_docs = self.vector_store.collection.get(
                where={"filename": filename},
                include=['metadatas', 'documents']
            )
            
            if not all_docs['ids']:
                return f"âš ï¸ æœªæ‰¾åˆ°æ–‡ä»¶: {filename}"
            
            # æŒ‰chunk_idæ’åº
            chunks_data = list(zip(
                all_docs['metadatas'],
                all_docs['documents']
            ))
            chunks_data.sort(key=lambda x: x[0].get('chunk_id', 0))
            
            # æ„å»ºé¢„è§ˆå†…å®¹
            total_chunks = len(chunks_data)
            preview_count = min(preview_chunks, total_chunks)
            
            result = f"# ğŸ“„ æ–‡æ¡£é¢„è§ˆ: {filename}\n\n"
            result += f"**æ€»å—æ•°**: {total_chunks} | **é¢„è§ˆå—æ•°**: {preview_count}\n\n"
            result += "---\n\n"
            
            for i in range(preview_count):
                metadata, content = chunks_data[i]
                chunk_id = metadata.get('chunk_id', i)
                result += f"### ğŸ“Œ Chunk {chunk_id + 1}/{total_chunks}\n\n"
                
                # æ˜¾ç¤ºmetadataä¿¡æ¯
                category = metadata.get('category', 'æœªåˆ†ç±»')
                file_type = metadata.get('file_type', 'æœªçŸ¥')
                result += f"**åˆ†ç±»**: {category} | **ç±»å‹**: {file_type}\n\n"
                
                # æ˜¾ç¤ºå†…å®¹ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
                preview_text = content[:500] if len(content) > 500 else content
                if len(content) > 500:
                    preview_text += "\n\n*ï¼ˆå†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­...ï¼‰*"
                
                result += f"```\n{preview_text}\n```\n\n"
                result += "---\n\n"
            
            if total_chunks > preview_count:
                result += f"\nğŸ’¡ *è¿˜æœ‰ {total_chunks - preview_count} ä¸ªchunkæœªæ˜¾ç¤º*"
            
            logger.info(f"æ–‡æ¡£é¢„è§ˆæˆåŠŸ: {filename}")
            return result
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£é¢„è§ˆå¤±è´¥: {str(e)}")
            return f"âŒ é¢„è§ˆå¤±è´¥: {str(e)}"
    
    def delete_document_by_filename(self, filename: str) -> str:
        """
        åˆ é™¤æŒ‡å®šæ–‡ä»¶åçš„æ‰€æœ‰æ–‡æ¡£å—
        
        Args:
            filename: è¦åˆ é™¤çš„æ–‡ä»¶å
            
        Returns:
            åˆ é™¤ç»“æœæ¶ˆæ¯
        """
        try:
            if not filename.strip():
                return "âš ï¸ è¯·è¾“å…¥è¦åˆ é™¤çš„æ–‡ä»¶å"
            
            logger.info(f"å‡†å¤‡åˆ é™¤æ–‡æ¡£: {filename}")
            
            # è°ƒç”¨åº•å±‚åˆ é™¤æ–¹æ³•
            success = self.vector_store.delete_documents({"filename": filename})
            
            if success:
                logger.info(f"æ–‡æ¡£åˆ é™¤æˆåŠŸ: {filename}")
                return f"âœ… å·²æˆåŠŸåˆ é™¤æ–‡ä»¶: {filename}\n\nğŸ’¡ æç¤ºï¼šè¯·åˆ·æ–°æ–‡æ¡£åˆ—è¡¨æŸ¥çœ‹æ›´æ–°"
            else:
                logger.warning(f"æ–‡æ¡£æœªæ‰¾åˆ°: {filename}")
                return f"âš ï¸ æœªæ‰¾åˆ°æ–‡ä»¶: {filename}\n\nğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦æ­£ç¡®ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰"
                
        except Exception as e:
            logger.error(f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {str(e)}")
            return f"âŒ åˆ é™¤å¤±è´¥: {str(e)}"
    
    def update_document(self, old_filename: str, file) -> str:
        """
        æ›´æ–°æ–‡æ¡£ï¼ˆå…ˆåˆ é™¤æ—§ç‰ˆæœ¬ï¼Œå†ä¸Šä¼ æ–°ç‰ˆæœ¬ï¼‰
        
        Args:
            old_filename: è¦åˆ é™¤çš„æ—§æ–‡ä»¶å
            file: æ–°ç‰ˆæœ¬æ–‡ä»¶å¯¹è±¡
            
        Returns:
            æ›´æ–°ç»“æœæ¶ˆæ¯
        """
        try:
            if not old_filename or not old_filename.strip():
                return "âš ï¸ è¯·è¾“å…¥è¦æ›´æ–°çš„æ–‡ä»¶å"
            
            if file is None:
                return "âš ï¸ è¯·é€‰æ‹©æ–°æ–‡ä»¶"
            
            logger.info(f"å¼€å§‹æ›´æ–°æ–‡æ¡£: {old_filename}")
            
            # 1. åˆ é™¤æ—§ç‰ˆæœ¬
            logger.info(f"åˆ é™¤æ—§ç‰ˆæœ¬: {old_filename}")
            delete_success = self.vector_store.delete_documents({"filename": old_filename})
            
            if not delete_success:
                logger.warning(f"æ—§æ–‡æ¡£æœªæ‰¾åˆ°: {old_filename}ï¼Œç»§ç»­ä¸Šä¼ æ–°æ–‡æ¡£")
            
            # 2. ä¸Šä¼ æ–°ç‰ˆæœ¬
            file_path = file.name if hasattr(file, 'name') else str(file)
            logger.info(f"ä¸Šä¼ æ–°ç‰ˆæœ¬: {file_path}")
            result = self.load_and_process_files([file_path])
            
            return f"âœ… æ–‡æ¡£æ›´æ–°æˆåŠŸï¼\n\næ—§æ–‡æ¡£: {old_filename}\næ–°æ–‡æ¡£: {Path(file_path).name}\n\n{result}"
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£æ›´æ–°å¤±è´¥: {str(e)}", exc_info=True)
            return f"âŒ æ›´æ–°å¤±è´¥: {str(e)}"

    def get_statistics(self) -> str:
        """
        è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            stats = self.vector_store.get_stats()

            if not stats:
                return "çŸ¥è¯†åº“ä¸ºç©ºæˆ–ç»Ÿè®¡æ•°æ®è·å–å¤±è´¥ã€‚"

            # è·å–æ–‡æ¡£åˆ—è¡¨
            file_list = self.get_document_list()

            result = "ğŸ“Š **çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯**\n\n"
            
            # æ–‡ä»¶å’Œå—ç»Ÿè®¡
            result += f"â€¢ ğŸ“ **æ–‡ä»¶æ•°**: {len(file_list)}\n"
            result += f"â€¢ ğŸ“„ **æ–‡æ¡£å—æ€»æ•°**: {stats.get('total_documents', 0)}\n"
            
            if len(file_list) > 0:
                avg_chunks = stats.get('total_documents', 0) / len(file_list)
                result += f"â€¢ ğŸ“Š **å¹³å‡åˆ†å—æ•°**: {avg_chunks:.1f}\n"
            
            # æŒ‰åˆ†ç±»ç»Ÿè®¡
            category_counts = {}
            for file_data in file_list:
                cat = file_data[2] if len(file_data) > 2 else 'æœªåˆ†ç±»'  # categoryåœ¨ç´¢å¼•2
                category_counts[cat] = category_counts.get(cat, 0) + 1
            
            if category_counts:
                result += f"\n**ğŸ“‚ åˆ†ç±»ç»Ÿè®¡**:\n"
                for cat, count in sorted(category_counts.items(), key=lambda x: -x[1]):
                    result += f"  â€¢ {cat}: {count}ä¸ªæ–‡ä»¶\n"
            
            # æ•°æ®åº“ä¿¡æ¯
            result += f"\nâ€¢ ğŸ—„ï¸ **æ•°æ®åº“è·¯å¾„**: {stats.get('vector_db_path', 'N/A')}\n"
            result += f"â€¢ ğŸ“¦ **é›†åˆåç§°**: {stats.get('collection_name', 'N/A')}\n"
            result += f"â€¢ ğŸ”¢ **å‘é‡ç»´åº¦**: {stats.get('embeddings_dimension', 'N/A')}\n"

            # Embeddingæ–¹æ³•ä¿¡æ¯
            if hasattr(self.vector_store, 'embedding_manager'):
                method_info = self.vector_store.embedding_manager.get_method_info()
                result += f"\n**ğŸ”§ Embeddingé…ç½®**:\n"
                result += f"  â€¢ æ–¹æ³•: {method_info['description']}\n"
                result += f"  â€¢ ç»´åº¦: {method_info['dimension']}\n"
                result += f"  â€¢ å…è´¹: {'æ˜¯ âœ…' if method_info['is_free'] else 'å¦'}\n"

            # æ˜¾ç¤ºLLMåŠŸèƒ½çŠ¶æ€
            if self.llm_enabled:
                result += f"\n**ğŸ¤– AIåŠŸèƒ½**: âœ… å·²å¯ç”¨ (DeepSeek)\n"
                # è·å–embeddingä¿¡æ¯
                if self.llm_manager and hasattr(self.llm_manager, 'get_embedding_info'):
                    embedding_info = self.llm_manager.get_embedding_info()
                    result += f"  â€¢ ğŸ”§ Embedding: {embedding_info['description']}\n"
            else:
                result += f"\n**ğŸ¤– AIåŠŸèƒ½**: âš ï¸ ç®€åŒ–æ¨¡å¼\n"
                result += f"  â€¢ ğŸ’¡ æç¤º: é…ç½®DEEPSEEK_API_KEYä»¥å¯ç”¨æ™ºèƒ½é—®ç­”\n"

            result += "\nğŸ’¡ *æç¤ºï¼šä¸Šä¼ æ›´å¤šæ–‡æ¡£ä»¥è·å¾—æ›´è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯*"

            return result

        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"

    def create_interface(self) -> gr.Interface:
        """åˆ›å»ºGradioç•Œé¢"""

        # è®¾ç½®Gradioä¸»é¢˜
        theme = gr.themes.Soft(
            primary_hue="blue",
            secondary_hue="gray",
            neutral_hue="slate"
        )

        with gr.Blocks(theme=theme, title=settings.APP_NAME) as demo:
            # æ ‡é¢˜
            gr.Markdown(
                f"""
                # ğŸ¤– {settings.APP_NAME} v{settings.APP_VERSION}
                
                åŸºäºLangChainå’ŒRAGæŠ€æœ¯çš„ä¸ªäººçŸ¥è¯†ç®¡ç†åŠ©æ‰‹
                
                æ”¯æŒæ–‡æ¡£ä¸Šä¼ ã€æ™ºèƒ½æ£€ç´¢ã€é—®ç­”äº¤äº’ç­‰åŠŸèƒ½
                """
            )

            with gr.Tabs():
                # Tab 1: æ–‡æ¡£ä¸Šä¼ 
                with gr.TabItem("ğŸ“¤ æ–‡æ¡£ä¸Šä¼ "):
                    with gr.Row():
                        file_input = gr.File(
                            label="é€‰æ‹©æ–‡æ¡£æ–‡ä»¶",
                            file_count="multiple",
                            file_types=[".pdf", ".txt", ".md", ".docx"]
                        )

                    with gr.Row():
                        upload_btn = gr.Button("ğŸš€ å¤„ç†æ–‡æ¡£", variant="primary")

                    upload_status = gr.Textbox(
                        label="å¤„ç†çŠ¶æ€",
                        lines=5,
                        max_lines=10
                    )

                    upload_btn.click(
                        self.load_and_process_files,
                        inputs=[file_input],
                        outputs=[upload_status]
                    ).then(
                        lambda: None,  # ä¸Šä¼ æˆåŠŸåæ¸…ç©ºæ–‡ä»¶é€‰æ‹©å™¨
                        outputs=[file_input]
                    )

                # Tab 2: æ™ºèƒ½é—®ç­”
                with gr.TabItem("ğŸ’¬ æ™ºèƒ½é—®ç­”"):
                    chatbot = gr.Chatbot(
                        label="å¯¹è¯å†å²",
                        height=500,
                        type='messages'
                    )

                    msg_input = gr.Textbox(
                        label="æ‚¨çš„é—®é¢˜",
                        placeholder="è¯·è¾“å…¥æ‚¨æƒ³äº†è§£çš„é—®é¢˜...",
                        scale=4
                    )

                    with gr.Row():
                        send_btn = gr.Button("ğŸ’­ æé—®", variant="primary")
                        clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯")

                    def process_user_message(message, history):
                        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶ç”ŸæˆAIå›ç­”"""
                        print(f"[DEBUG] process_user_message called! Message: {message}")
                        print(f"[DEBUG] Current history length: {len(history) if history else 0}")

                        if not message or not message.strip():
                            return "", history or []

                        try:
                            # è°ƒç”¨chat_with_knowledgeå‡½æ•°ç”Ÿæˆå›ç­”
                            ai_response = self.chat_with_knowledge(message, history or [])

                            # æ„å»ºæ–°çš„å¯¹è¯å†å²ï¼ˆæ·»åŠ ç”¨æˆ·é—®é¢˜å’ŒAIå›ç­”ï¼‰
                            new_history = (history or []) + [
                                {"role": "user", "content": message},
                                {"role": "assistant", "content": ai_response}
                            ]

                            # é™åˆ¶å†å²é•¿åº¦ï¼ˆä¿ç•™æœ€è¿‘10è½®å¯¹è¯ = 20æ¡æ¶ˆæ¯ï¼‰
                            if len(new_history) > 20:
                                new_history = new_history[-20:]

                            print(f"[DEBUG] Generated response, total history entries: {len(new_history)}")

                            # è¿”å›æ¸…ç©ºçš„è¾“å…¥æ¡†å’Œå®Œæ•´çš„å¯¹è¯å†å²
                            return "", new_history

                        except Exception as e:
                            print(f"[ERROR] Failed to process message: {str(e)}")
                            error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {str(e)}"

                            # æ„å»ºé”™è¯¯æƒ…å†µä¸‹çš„å¯¹è¯å†å²
                            new_history = (history or []) + [
                                {"role": "user", "content": message},
                                {"role": "assistant", "content": error_msg}
                            ]

                            return "", new_history

                    def clear_chat():
                        """æ¸…ç©ºå¯¹è¯å†å²"""
                        print(f"[DEBUG] Chat history cleared")
                        return []

                    # ç»‘å®šäº‹ä»¶å¤„ç†å™¨
                    msg_input.submit(
                        process_user_message,
                        inputs=[msg_input, chatbot],
                        outputs=[msg_input, chatbot]
                    )

                    send_btn.click(
                        process_user_message,
                        inputs=[msg_input, chatbot],
                        outputs=[msg_input, chatbot]
                    )

                    clear_btn.click(
                        clear_chat,
                        outputs=[chatbot]
                    )

                # Tab 3: æœç´¢åŠŸèƒ½
                with gr.TabItem("ğŸ” æ–‡æ¡£æœç´¢"):
                    with gr.Row():
                        with gr.Column(scale=3):
                            search_input = gr.Textbox(
                                label="æœç´¢å…³é”®è¯",
                                placeholder="è¾“å…¥å…³é”®è¯è¿›è¡Œæœç´¢..."
                            )
                        with gr.Column(scale=1):
                            history_dropdown = gr.Dropdown(
                                label="ğŸ“ æœç´¢å†å²",
                                choices=[],
                                interactive=True,
                                allow_custom_value=False
                            )

                    with gr.Row():
                        search_mode = gr.Dropdown(
                            choices=["æ··åˆæ£€ç´¢", "è¯­ä¹‰æ£€ç´¢"],
                            value="æ··åˆæ£€ç´¢",
                            label="æœç´¢æ¨¡å¼"
                        )

                        top_k_slider = gr.Slider(
                            minimum=1,
                            maximum=20,
                            value=5,
                            step=1,
                            label="è¿”å›ç»“æœæ•°é‡",
                            elem_id="top_k_slider"
                        )

                    with gr.Row():
                        search_btn = gr.Button("ğŸ” æœç´¢", variant="primary")
                        refresh_history_btn = gr.Button("ğŸ”„ åˆ·æ–°å†å²")
                        clear_history_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå†å²")

                    search_results = gr.Textbox(
                        label="æœç´¢ç»“æœ",
                        lines=15,
                        max_lines=20
                    )

                    # æœç´¢å†å²æ˜¾ç¤º
                    with gr.Accordion("ğŸ“‹ æœç´¢å†å²è®°å½•", open=False):
                        history_display = gr.Markdown(value="æš‚æ— æœç´¢å†å²")

                    # å®šä¹‰è¾…åŠ©å‡½æ•°
                    def refresh_history_dropdown():
                        """åˆ·æ–°å†å²ä¸‹æ‹‰èœå•"""
                        choices = self.search_history_manager.get_history_dropdown_choices(20)
                        return gr.Dropdown(choices=choices)

                    def refresh_history_display():
                        """åˆ·æ–°å†å²æ˜¾ç¤º"""
                        return self.search_history_manager.format_history_for_display(15)

                    def clear_search_history():
                        """æ¸…ç©ºæœç´¢å†å²"""
                        self.search_history_manager.clear_history()
                        return gr.Dropdown(choices=[]), "âœ… æœç´¢å†å²å·²æ¸…ç©º"

                    def use_history_query(selected_query):
                        """ä½¿ç”¨å†å²æŸ¥è¯¢"""
                        if selected_query:
                            return selected_query
                        return ""

                    # ç»‘å®šäº‹ä»¶
                    search_btn.click(
                        self.search_knowledge,
                        inputs=[search_input, search_mode, top_k_slider],
                        outputs=[search_results]
                    ).then(
                        refresh_history_dropdown,
                        outputs=[history_dropdown]
                    ).then(
                        refresh_history_display,
                        outputs=[history_display]
                    )
                    
                    # æ”¯æŒEnteré”®æœç´¢
                    search_input.submit(
                        self.search_knowledge,
                        inputs=[search_input, search_mode, top_k_slider],
                        outputs=[search_results]
                    ).then(
                        refresh_history_dropdown,
                        outputs=[history_dropdown]
                    ).then(
                        refresh_history_display,
                        outputs=[history_display]
                    )

                    # ç‚¹å‡»å†å²è®°å½•å¡«å……åˆ°æœç´¢æ¡†
                    history_dropdown.change(
                        use_history_query,
                        inputs=[history_dropdown],
                        outputs=[search_input]
                    )

                    # åˆ·æ–°å†å²æŒ‰é’®
                    refresh_history_btn.click(
                        refresh_history_dropdown,
                        outputs=[history_dropdown]
                    ).then(
                        refresh_history_display,
                        outputs=[history_display]
                    )

                    # æ¸…ç©ºå†å²æŒ‰é’®
                    clear_history_btn.click(
                        clear_search_history,
                        outputs=[history_dropdown, search_results]
                    ).then(
                        refresh_history_display,
                        outputs=[history_display]
                    )

                # Tab 4: ç»Ÿè®¡ä¿¡æ¯
                with gr.TabItem("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯"):
                    stats_btn = gr.Button("ğŸ“ˆ è·å–ç»Ÿè®¡ä¿¡æ¯", variant="primary")
                    stats_display = gr.Textbox(
                        label="ç»Ÿè®¡ä¿¡æ¯",
                        lines=15,
                        max_lines=20
                    )

                    stats_btn.click(
                        self.get_statistics,
                        outputs=[stats_display]
                    )

                # Tab 5: æ–‡æ¡£ç®¡ç†
                with gr.TabItem("ğŸ—‚ï¸ æ–‡æ¡£ç®¡ç†"):
                    gr.Markdown(
                        """
                        ### ğŸ“ çŸ¥è¯†åº“æ–‡æ¡£ç®¡ç†
                        
                        åœ¨è¿™é‡Œæ‚¨å¯ä»¥æŸ¥çœ‹ã€åˆ é™¤å’Œæ›´æ–°çŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£ã€‚
                        
                        ğŸ’¡ **æç¤º**: ç‚¹å‡»æ–‡ä»¶åå¯ä»¥è‡ªåŠ¨å¡«å……åˆ°ä¸‹æ–¹çš„åˆ é™¤/æ›´æ–°è¾“å…¥æ¡†
                        """
                    )
                    
                    # åˆ·æ–°æŒ‰é’®
                    with gr.Row():
                        refresh_list_btn = gr.Button("ğŸ”„ åˆ·æ–°æ–‡æ¡£åˆ—è¡¨", variant="primary")
                    
                    # æ–‡æ¡£åˆ—è¡¨å±•ç¤º
                    file_list_display = gr.Dataframe(
                        headers=["æ–‡ä»¶å", "åˆ†å—æ•°", "åˆ†ç±»", "ç±»å‹", "æ–‡ä»¶å¤§å°", "æœ€åæ›´æ–°"],
                        label="çŸ¥è¯†åº“æ–‡æ¡£åˆ—è¡¨",
                        interactive=False,
                        wrap=True
                    )
                    
                    gr.Markdown("---")
                    
                    # åˆ é™¤æ–‡æ¡£åŠŸèƒ½
                    with gr.Row():
                        with gr.Column(scale=3):
                            delete_filename_input = gr.Textbox(
                                label="ğŸ“ è¦åˆ é™¤çš„æ–‡ä»¶å",
                                placeholder="è¾“å…¥å®Œæ•´çš„æ–‡ä»¶åï¼ˆå¦‚ï¼špython_learning_notes.mdï¼‰",
                                info="è¯·ä»ä¸Šæ–¹åˆ—è¡¨ä¸­å¤åˆ¶æ–‡ä»¶å"
                            )
                        with gr.Column(scale=1):
                            delete_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤æ–‡æ¡£", variant="stop")
                    
                    delete_status = gr.Textbox(
                        label="åˆ é™¤çŠ¶æ€",
                        lines=3,
                        max_lines=5
                    )
                    
                    gr.Markdown("---")
                    
                    # æ›´æ–°æ–‡æ¡£åŠŸèƒ½
                    gr.Markdown("### ğŸ”„ æ›´æ–°æ–‡æ¡£")
                    
                    with gr.Row():
                        update_filename_input = gr.Textbox(
                            label="ğŸ“ è¦æ›´æ–°çš„æ–‡ä»¶å",
                            placeholder="è¾“å…¥è¦æ›¿æ¢çš„æ–‡æ¡£åç§°ï¼ˆå¦‚ï¼špython_learning_notes.mdï¼‰",
                            info="æ—§æ–‡æ¡£å°†è¢«åˆ é™¤ï¼Œæ–°æ–‡æ¡£å°†è¢«ä¸Šä¼ "
                        )
                    
                    with gr.Row():
                        update_file_input = gr.File(
                            label="ğŸ“¤ é€‰æ‹©æ–°æ–‡æ¡£",
                            file_count="single",
                            file_types=[".pdf", ".txt", ".md", ".docx"]
                        )
                    
                    with gr.Row():
                        update_btn = gr.Button("ğŸ”„ æ›´æ–°æ–‡æ¡£", variant="primary")
                    
                    update_status = gr.Textbox(
                        label="æ›´æ–°çŠ¶æ€",
                        lines=5,
                        max_lines=10
                    )
                    
                    gr.Markdown("---")
                    
                    # æ–‡æ¡£é¢„è§ˆåŠŸèƒ½
                    gr.Markdown("### ğŸ‘€ æ–‡æ¡£é¢„è§ˆ")
                    
                    with gr.Row():
                        with gr.Column(scale=2):
                            preview_filename_input = gr.Textbox(
                                label="ğŸ“ è¦é¢„è§ˆçš„æ–‡ä»¶å",
                                placeholder="è¾“å…¥å®Œæ•´çš„æ–‡ä»¶åï¼ˆå¦‚ï¼špython_learning_notes.mdï¼‰",
                                info="è¯·ä»ä¸Šæ–¹åˆ—è¡¨ä¸­å¤åˆ¶æ–‡ä»¶å"
                            )
                        with gr.Column(scale=1):
                            preview_chunks_slider = gr.Slider(
                                minimum=1,
                                maximum=10,
                                value=3,
                                step=1,
                                label="é¢„è§ˆå—æ•°",
                                info="é€‰æ‹©è¦é¢„è§ˆçš„chunkæ•°é‡"
                            )
                        with gr.Column(scale=1):
                            preview_btn = gr.Button("ğŸ‘€ é¢„è§ˆæ–‡æ¡£", variant="primary")
                    
                    preview_display = gr.Markdown(
                        label="æ–‡æ¡£é¢„è§ˆ",
                        value="ç‚¹å‡»'é¢„è§ˆæ–‡æ¡£'æŒ‰é’®æŸ¥çœ‹æ–‡æ¡£å†…å®¹"
                    )
                    
                    # ç»‘å®šäº‹ä»¶å¤„ç†å™¨
                    def refresh_file_list():
                        """åˆ·æ–°æ–‡ä»¶åˆ—è¡¨å¹¶è¿”å›æ ¼å¼åŒ–çš„æ•°æ®"""
                        try:
                            file_list = self.get_document_list()
                            # get_document_list() å·²ç»è¿”å›åˆ—è¡¨æ ¼å¼ï¼Œç›´æ¥è¿”å›å³å¯
                            return file_list if file_list else [["æš‚æ— æ–‡æ¡£", "0", "-", "-", "-", "-"]]
                        
                        except Exception as e:
                            logger.error(f"åˆ·æ–°æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")
                            return [["é”™è¯¯", str(e), "-", "-", "-", "-"]]
                    
                    def select_file_from_list(evt: gr.SelectData):
                        """ä»åˆ—è¡¨ä¸­é€‰æ‹©æ–‡ä»¶ï¼Œè‡ªåŠ¨å¡«å……æ–‡ä»¶å"""
                        if evt.value:
                            # evt.value æ˜¯é€‰ä¸­å•å…ƒæ ¼çš„å€¼
                            # evt.index æ˜¯ [row, col]
                            row, col = evt.index
                            file_list = self.get_document_list()
                            if row < len(file_list):
                                filename = file_list[row][0]  # ç¬¬ä¸€åˆ—æ˜¯æ–‡ä»¶å
                                return filename, filename, filename
                        return "", "", ""
                    
                    # ç»‘å®šæŒ‰é’®äº‹ä»¶
                    refresh_list_btn.click(
                        refresh_file_list,
                        outputs=[file_list_display]
                    )
                    
                    # ç‚¹å‡»è¡¨æ ¼è‡ªåŠ¨å¡«å……æ–‡ä»¶å
                    file_list_display.select(
                        select_file_from_list,
                        outputs=[delete_filename_input, update_filename_input, preview_filename_input]
                    )
                    
                    delete_btn.click(
                        self.delete_document_by_filename,
                        inputs=[delete_filename_input],
                        outputs=[delete_status]
                    ).then(
                        refresh_file_list,  # åˆ é™¤åè‡ªåŠ¨åˆ·æ–°åˆ—è¡¨
                        outputs=[file_list_display]
                    ).then(
                        lambda: "",  # åˆ é™¤åæ¸…ç©ºè¾“å…¥æ¡†
                        outputs=[delete_filename_input]
                    )
                    
                    update_btn.click(
                        self.update_document,
                        inputs=[update_filename_input, update_file_input],
                        outputs=[update_status]
                    ).then(
                        refresh_file_list,  # æ›´æ–°åè‡ªåŠ¨åˆ·æ–°åˆ—è¡¨
                        outputs=[file_list_display]
                    ).then(
                        lambda: ("", None),  # æ›´æ–°åæ¸…ç©ºè¾“å…¥æ¡†å’Œæ–‡ä»¶é€‰æ‹©å™¨
                        outputs=[update_filename_input, update_file_input]
                    )
                    
                    # ç»‘å®šé¢„è§ˆäº‹ä»¶
                    preview_btn.click(
                        self.preview_document,
                        inputs=[preview_filename_input, preview_chunks_slider],
                        outputs=[preview_display]
                    )

            # é¡µè„š
            gr.Markdown(
                """
                ---
                
                ## ğŸš€ ä½¿ç”¨è¯´æ˜
                
                1. **ä¸Šä¼ æ–‡æ¡£**: é€‰æ‹©æ–‡æ¡£æ–‡ä»¶å¹¶ç‚¹å‡»"å¤„ç†æ–‡æ¡£"
                2. **æ™ºèƒ½é—®ç­”**: åœ¨å¯¹è¯ä¸­è¾“å…¥é—®é¢˜ï¼Œç³»ç»Ÿå°†åŸºäºçŸ¥è¯†åº“å›ç­”
                3. **æ–‡æ¡£æœç´¢**: ä½¿ç”¨å…³é”®è¯æœç´¢ç›¸å…³æ–‡æ¡£å†…å®¹
                4. **æŸ¥çœ‹ç»Ÿè®¡**: äº†è§£çŸ¥è¯†åº“çš„æ•´ä½“çŠ¶å†µ
                
                ## âš™ï¸ æŠ€æœ¯ç‰¹æ€§
                
                - ğŸ§  **æ™ºèƒ½æ¶æ„**: è‡ªåŠ¨é€‰æ‹©æœ€ä½³embeddingæ–¹æ³• (OpenAI â†’ Sentence Transformers â†’ text-hash)
                - ğŸ“š **RAGæŠ€æœ¯**: æ£€ç´¢å¢å¼ºç”Ÿæˆï¼Œç¡®ä¿ç­”æ¡ˆå‡†ç¡®
                - ğŸ” **æ··åˆæœç´¢**: å‘é‡æœç´¢ + å…³é”®è¯æœç´¢
                - ğŸ’¡ **æ™ºèƒ½åˆ†ç±»**: è‡ªåŠ¨æ–‡æ¡£åˆ†ç±»å’Œæ ‡ç­¾
                - ğŸ“Š **æˆæœ¬ä¼˜åŒ–**: æ— APIè´¹ç”¨ + æ™ºèƒ½é™çº§ç­–ç•¥
                - ğŸ”„ **è‡ªåŠ¨å›é€€**: APIä¸å¯ç”¨æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å…è´¹æ–¹æ¡ˆ
                """
            )

        return demo

def create_app() -> gr.Interface:
    """åˆ›å»ºåº”ç”¨å®ä¾‹"""
    app = KnowledgeManagerApp()
    return app.create_interface()

if __name__ == "__main__":
    # åˆ›å»ºå¹¶å¯åŠ¨åº”ç”¨
    interface = create_app()

    # å¯åŠ¨æœåŠ¡å™¨
    interface.launch(
        server_name=settings.GRADIO_SERVER_HOST,
        server_port=settings.GRADIO_SERVER_PORT,
        share=settings.GRADIO_SHARE,
        debug=settings.GRADIO_DEBUG,
        show_error=True,
        quiet=False
    )
