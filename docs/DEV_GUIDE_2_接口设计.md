# ä¸ªäººçŸ¥è¯†ç®¡ç†Agentç³»ç»Ÿ - æ¥å£è®¾è®¡æ–‡æ¡£

## æ–‡æ¡£ä¿¡æ¯
- **ç‰ˆæœ¬**: v1.0.0
- **åˆ›å»ºæ—¥æœŸ**: 2025-11-07
- **é€‚ç”¨äººå‘˜**: åç«¯å¼€å‘ã€å‰ç«¯å¼€å‘ã€APIé›†æˆå¼€å‘è€…

---

## 1. æ¥å£è®¾è®¡æ¦‚è¿°

æœ¬ç³»ç»Ÿé‡‡ç”¨**å†…éƒ¨API**è®¾è®¡ï¼Œå„æ¨¡å—é€šè¿‡Pythonç±»æ–¹æ³•è¿›è¡Œäº¤äº’ã€‚å‰ç«¯ä½¿ç”¨Gradioæ¡†æ¶ï¼Œé€šè¿‡å‡½æ•°å›è°ƒä¸åç«¯é€šä¿¡ã€‚

### 1.1 æ¥å£åˆ†ç±»

| æ¥å£ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|---------|------|------|
| **å†…éƒ¨Python API** | æ¨¡å—é—´Pythonæ–¹æ³•è°ƒç”¨ | `DocumentLoader.load_file()` |
| **Gradio UIäº‹ä»¶** | ç”¨æˆ·ç•Œé¢äº¤äº’äº‹ä»¶ | æŒ‰é’®ç‚¹å‡»ã€æ–‡ä»¶ä¸Šä¼  |
| **å¤–éƒ¨APIè°ƒç”¨** | è°ƒç”¨ç¬¬ä¸‰æ–¹æœåŠ¡ | OpenAI APIã€DeepSeek API |

---

## 2. æ ¸å¿ƒæ¨¡å—APIè®¾è®¡

### 2.1 æ–‡æ¡£åŠ è½½æ¨¡å— (DocumentLoader)

#### ç±»å®šä¹‰
```python
class DocumentLoader:
    """æ–‡æ¡£åŠ è½½å’Œå¤„ç†å™¨"""
```

#### 2.1.1 load_file()
**åŠŸèƒ½**: åŠ è½½å•ä¸ªæ–‡æ¡£æ–‡ä»¶å¹¶åˆ†å—

**æ–¹æ³•ç­¾å**:
```python
def load_file(self, file_path: str) -> List[LangChainDocument]
```

**å‚æ•°è¯´æ˜**:
| å‚æ•°å | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|--------|------|------|------|
| file_path | str | âœ… | æ–‡æ¡£æ–‡ä»¶ç»å¯¹è·¯å¾„ |

**è¿”å›å€¼**:
```python
List[LangChainDocument]  # æ–‡æ¡£å—åˆ—è¡¨
```

**è¿”å›çš„Documentç»“æ„**:
```python
LangChainDocument(
    page_content="æ–‡æ¡£æ–‡æœ¬å†…å®¹",
    metadata={
        "source": "/path/to/file.pdf",
        "filename": "file.pdf",
        "chunk_id": 0,
        "total_chunks": 5,
        "file_type": ".pdf",
        "file_size": 2.5,  # MB
        "content_hash": "hash_value"
    }
)
```

**å¼‚å¸¸**:
- `FileNotFoundError`: æ–‡ä»¶ä¸å­˜åœ¨
- `ValueError`: æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒæˆ–æ–‡ä»¶è¿‡å¤§
- `Exception`: æ–‡æ¡£è§£æå¤±è´¥

**ä½¿ç”¨ç¤ºä¾‹**:
```python
loader = DocumentLoader()
try:
    documents = loader.load_file("/path/to/document.pdf")
    print(f"æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£å—")
except FileNotFoundError:
    print("æ–‡ä»¶ä¸å­˜åœ¨")
```

#### 2.1.2 load_multiple_files()
**åŠŸèƒ½**: æ‰¹é‡åŠ è½½å¤šä¸ªæ–‡æ¡£

**æ–¹æ³•ç­¾å**:
```python
def load_multiple_files(self, file_paths: List[str]) -> List[LangChainDocument]
```

**å‚æ•°è¯´æ˜**:
| å‚æ•°å | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|--------|------|------|------|
| file_paths | List[str] | âœ… | æ–‡ä»¶è·¯å¾„åˆ—è¡¨ |

**è¿”å›å€¼**:
```python
List[LangChainDocument]  # æ‰€æœ‰æ–‡æ¡£çš„å—åˆ—è¡¨
```

**ç‰¹æ€§**:
- é‡åˆ°é”™è¯¯è‡ªåŠ¨è·³è¿‡ï¼Œä¸ä¸­æ–­æ•´ä½“æµç¨‹
- è¿”å›æ‰€æœ‰æˆåŠŸåŠ è½½çš„æ–‡æ¡£å—

---

### 2.2 å‘é‡å­˜å‚¨æ¨¡å— (VectorStore)

#### ç±»å®šä¹‰
```python
class VectorStore:
    """å‘é‡æ•°æ®åº“ç®¡ç†å™¨"""
```

#### 2.2.1 add_documents()
**åŠŸèƒ½**: æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“

**æ–¹æ³•ç­¾å**:
```python
def add_documents(self, documents: List[LangChainDocument]) -> bool
```

**å‚æ•°è¯´æ˜**:
| å‚æ•°å | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|--------|------|------|------|
| documents | List[LangChainDocument] | âœ… | å¾…æ·»åŠ çš„æ–‡æ¡£åˆ—è¡¨ |

**è¿”å›å€¼**:
```python
bool  # True: æˆåŠŸ, False: å¤±è´¥
```

**å¤„ç†æµç¨‹**:
1. æå–æ–‡æ¡£æ–‡æœ¬å†…å®¹
2. ç”Ÿæˆembeddingå‘é‡
3. å­˜å‚¨åˆ°ChromaDB
4. è¿”å›æ“ä½œç»“æœ

**ä½¿ç”¨ç¤ºä¾‹**:
```python
vector_store = VectorStore()
success = vector_store.add_documents(documents)
if success:
    print("æ–‡æ¡£æ·»åŠ æˆåŠŸ")
```

#### 2.2.2 search()
**åŠŸèƒ½**: æœç´¢ç›¸å…³æ–‡æ¡£

**æ–¹æ³•ç­¾å**:
```python
def search(
    self, 
    query: str, 
    k: int = 5, 
    filter_dict: Optional[Dict] = None
) -> List[LangChainDocument]
```

**å‚æ•°è¯´æ˜**:
| å‚æ•°å | ç±»å‹ | å¿…å¡« | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|------|--------|------|
| query | str | âœ… | - | æœç´¢æŸ¥è¯¢æ–‡æœ¬ |
| k | int | âŒ | 5 | è¿”å›ç»“æœæ•°é‡ |
| filter_dict | Dict | âŒ | None | å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶ |

**filter_dict ç¤ºä¾‹**:
```python
{
    "filename": "python_notes.md",
    "category": "å­¦ä¹ "
}
```

**è¿”å›å€¼**:
```python
List[LangChainDocument]  # æŒ‰ç›¸å…³æ€§æ’åºçš„æ–‡æ¡£åˆ—è¡¨
```

**è¿”å›DocumentåŒ…å«çš„è¯„åˆ†å­—æ®µ**:
```python
metadata={
    # åŸå§‹å…ƒæ•°æ® ...
    "search_score": 0.85,      # è·ç¦»åˆ†æ•°
    "relevance_score": 0.75,   # ç›¸å…³æ€§åˆ†æ•° (0-1)
    "doc_id": "doc_xxx"
}
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
results = vector_store.search(
    query="Pythonè£…é¥°å™¨å¦‚ä½•ä½¿ç”¨?",
    k=5,
    filter_dict={"category": "å­¦ä¹ "}
)
```

#### 2.2.3 delete_documents()
**åŠŸèƒ½**: åˆ é™¤æŒ‡å®šæ–‡æ¡£

**æ–¹æ³•ç­¾å**:
```python
def delete_documents(self, filter_dict: Dict[str, Any]) -> bool
```

**å‚æ•°è¯´æ˜**:
| å‚æ•°å | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|--------|------|------|------|
| filter_dict | Dict[str, Any] | âœ… | åˆ é™¤æ¡ä»¶ |

**å¸¸ç”¨åˆ é™¤æ¡ä»¶**:
```python
# æŒ‰æ–‡ä»¶ååˆ é™¤
{"filename": "old_document.pdf"}

# æŒ‰åˆ†ç±»åˆ é™¤
{"category": "ä¸´æ—¶"}
```

**è¿”å›å€¼**:
```python
bool  # True: æˆåŠŸ, False: å¤±è´¥
```

#### 2.2.4 get_stats()
**åŠŸèƒ½**: è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯

**æ–¹æ³•ç­¾å**:
```python
def get_stats(self) -> Dict[str, Any]
```

**è¿”å›å€¼ç¤ºä¾‹**:
```python
{
    "collection_name": "knowledge_base",
    "total_documents": 150,
    "vector_db_path": "./data/vector_db",
    "embedding_method": "sentence-transformers",
    "embeddings_dimension": 384,
    "embedding_description": "Sentence Transformers (all-MiniLM-L6-v2)",
    "is_free_embedding": True,
    "privacy_protected": True
}
```

---

### 2.3 Embeddingç®¡ç†æ¨¡å— (EmbeddingManager)

#### ç±»å®šä¹‰
```python
class EmbeddingManager:
    """å¤šæ–¹æ¡ˆEmbeddingç®¡ç†å™¨"""
```

#### 2.3.1 embed_documents()
**åŠŸèƒ½**: æ‰¹é‡ç”Ÿæˆæ–‡æ¡£embedding

**æ–¹æ³•ç­¾å**:
```python
def embed_documents(self, texts: List[str]) -> List[List[float]]
```

**å‚æ•°è¯´æ˜**:
| å‚æ•°å | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|--------|------|------|------|
| texts | List[str] | âœ… | æ–‡æœ¬åˆ—è¡¨ |

**è¿”å›å€¼**:
```python
List[List[float]]  # embeddingå‘é‡åˆ—è¡¨ï¼Œæ¯ä¸ªå‘é‡ç»´åº¦æ ¹æ®æ–¹æ¡ˆè€Œå®š
```

**å‘é‡ç»´åº¦è¯´æ˜**:
| æ–¹æ¡ˆ | ç»´åº¦ |
|------|------|
| Sentence Transformers | 384 |
| æ–‡æœ¬å“ˆå¸Œ | 384 |
| TF-IDF | 1000 |
| OpenAI | 1536 |

#### 2.3.2 embed_query()
**åŠŸèƒ½**: ç”Ÿæˆå•ä¸ªæŸ¥è¯¢çš„embedding

**æ–¹æ³•ç­¾å**:
```python
def embed_query(self, text: str) -> List[float]
```

**å‚æ•°è¯´æ˜**:
| å‚æ•°å | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|--------|------|------|------|
| text | str | âœ… | æŸ¥è¯¢æ–‡æœ¬ |

**è¿”å›å€¼**:
```python
List[float]  # embeddingå‘é‡
```

#### 2.3.3 get_method_info()
**åŠŸèƒ½**: è·å–å½“å‰embeddingæ–¹æ³•ä¿¡æ¯

**æ–¹æ³•ç­¾å**:
```python
def get_method_info(self) -> Dict[str, Any]
```

**è¿”å›å€¼ç¤ºä¾‹**:
```python
{
    "method": "sentence-transformers",
    "dimension": 384,
    "description": "Sentence Transformers (all-MiniLM-L6-v2) - å…è´¹é«˜è´¨é‡",
    "is_free": True,
    "privacy_protected": True
}
```

---

### 2.4 LLMç®¡ç†æ¨¡å— (LLMManager)

#### ç±»å®šä¹‰
```python
class LLMManager:
    """LLMæ¨¡å‹ç®¡ç†å™¨"""
```

#### 2.4.1 åˆå§‹åŒ–
**æ–¹æ³•ç­¾å**:
```python
def __init__(self)
```

**åŠŸèƒ½**:
- è‡ªåŠ¨åˆå§‹åŒ–embeddingæ¨¡å‹
- è‡ªåŠ¨åˆå§‹åŒ–èŠå¤©æ¨¡å‹ï¼ˆå¦‚æœæœ‰APIå¯†é’¥ï¼‰
- æ™ºèƒ½é™çº§ç­–ç•¥

#### 2.4.2 embed_documents() / embed_query()
ä¸ `EmbeddingManager` ç›¸åŒæ¥å£ï¼Œç»Ÿä¸€ç®¡ç†

---

### 2.5 RAGç”Ÿæˆæ¨¡å— (RAGGenerator)

#### ç±»å®šä¹‰
```python
class RAGGenerator:
    """RAGé—®ç­”ç”Ÿæˆå™¨"""
```

#### 2.5.1 generate_answer()
**åŠŸèƒ½**: åŸºäºæ£€ç´¢æ–‡æ¡£ç”Ÿæˆæ™ºèƒ½å›ç­”

**æ–¹æ³•ç­¾å**:
```python
def generate_answer(
    self,
    query: str,
    documents: List[LangChainDocument],
    include_sources: bool = True
) -> Dict[str, Any]
```

**å‚æ•°è¯´æ˜**:
| å‚æ•°å | ç±»å‹ | å¿…å¡« | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|------|--------|------|
| query | str | âœ… | - | ç”¨æˆ·é—®é¢˜ |
| documents | List[LangChainDocument] | âœ… | - | æ£€ç´¢åˆ°çš„æ–‡æ¡£ |
| include_sources | bool | âŒ | True | æ˜¯å¦åŒ…å«æ¥æºå¼•ç”¨ |

**è¿”å›å€¼ç»“æ„**:
```python
{
    "answer": "åŸºäºä¸Šä¸‹æ–‡çš„AIå›ç­”...",
    "confidence": 0.85,  # ç½®ä¿¡åº¦ 0-1
    "sources": [
        {
            "filename": "python_notes.md",
            "relevance_score": 0.92,
            "chunk_id": 3
        }
    ],
    "metadata": {
        "query": "ç”¨æˆ·åŸå§‹é—®é¢˜",
        "retrieved_docs": 5,
        "model_used": "deepseek-chat",
        "tokens_used": 450
    }
}
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
rag_gen = RAGGenerator(llm_manager)
result = rag_gen.generate_answer(
    query="ä»€ä¹ˆæ˜¯Pythonè£…é¥°å™¨?",
    documents=retrieved_docs
)
print(result['answer'])
print(f"ç½®ä¿¡åº¦: {result['confidence']}")
```

#### 2.5.2 classify_document()
**åŠŸèƒ½**: ä½¿ç”¨LLMå¯¹æ–‡æ¡£è¿›è¡Œæ™ºèƒ½åˆ†ç±»

**æ–¹æ³•ç­¾å**:
```python
def classify_document(self, content: str) -> Dict[str, Any]
```

**å‚æ•°è¯´æ˜**:
| å‚æ•°å | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|--------|------|------|------|
| content | str | âœ… | æ–‡æ¡£å†…å®¹ï¼ˆæœ€å¤š2000å­—ç¬¦ï¼‰ |

**è¿”å›å€¼ç»“æ„**:
```python
{
    "category": "å­¦ä¹ ",
    "priority": "é«˜",
    "summary": "å…³äºPythonè£…é¥°å™¨çš„å­¦ä¹ ç¬”è®°...",
    "tags": ["Python", "è£…é¥°å™¨", "é«˜çº§ç‰¹æ€§"],
    "confidence": 0.9
}
```

---

### 2.6 æ··åˆæ£€ç´¢æ¨¡å— (HybridRetriever)

#### ç±»å®šä¹‰
```python
class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨ï¼ˆå‘é‡+å…³é”®è¯ï¼‰"""
```

#### 2.6.1 hybrid_search()
**åŠŸèƒ½**: æ··åˆæ£€ç´¢ï¼ˆå‘é‡æœç´¢ + å…³é”®è¯æœç´¢ï¼‰

**æ–¹æ³•ç­¾å**:
```python
def hybrid_search(
    self,
    query: str,
    k: int = 5,
    vector_weight: float = 0.7,
    keyword_weight: float = 0.3,
    filter_dict: Optional[Dict] = None
) -> List[LangChainDocument]
```

**å‚æ•°è¯´æ˜**:
| å‚æ•°å | ç±»å‹ | å¿…å¡« | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|------|--------|------|
| query | str | âœ… | - | æœç´¢æŸ¥è¯¢ |
| k | int | âŒ | 5 | è¿”å›ç»“æœæ•° |
| vector_weight | float | âŒ | 0.7 | å‘é‡æœç´¢æƒé‡ |
| keyword_weight | float | âŒ | 0.3 | å…³é”®è¯æœç´¢æƒé‡ |
| filter_dict | Dict | âŒ | None | å…ƒæ•°æ®è¿‡æ»¤ |

**è¿”å›DocumentåŒ…å«çš„è¯„åˆ†**:
```python
metadata={
    # åŸå§‹å…ƒæ•°æ® ...
    "vector_score": 0.85,      # å‘é‡æœç´¢åˆ†æ•°
    "keyword_score": 0.60,     # å…³é”®è¯æœç´¢åˆ†æ•°
    "combined_score": 0.78     # ç»¼åˆåˆ†æ•°
}
```

**æ³¨æ„**: å½“å‰ç‰ˆæœ¬å…³é”®è¯æœç´¢éƒ¨åˆ†**æœªå®Œå…¨å®ç°**ï¼ˆTODOï¼‰ï¼Œä¸»è¦ä¾èµ–å‘é‡æœç´¢ã€‚

---

### 2.7 æ–‡æ¡£åˆ†ç±»æ¨¡å— (DocumentClassifier)

#### ç±»å®šä¹‰
```python
class DocumentClassifier:
    """æ–‡æ¡£æ™ºèƒ½åˆ†ç±»å™¨"""
```

#### 2.7.1 classify_document()
**åŠŸèƒ½**: åŸºäºè§„åˆ™å¯¹æ–‡æ¡£åˆ†ç±»

**æ–¹æ³•ç­¾å**:
```python
def classify_document(self, document: LangChainDocument) -> Dict[str, Any]
```

**å‚æ•°è¯´æ˜**:
| å‚æ•°å | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|--------|------|------|------|
| document | LangChainDocument | âœ… | å¾…åˆ†ç±»æ–‡æ¡£ |

**è¿”å›å€¼ç»“æ„**:
```python
{
    "category": "å­¦ä¹ ",        # åˆ†ç±»: å·¥ä½œ/å­¦ä¹ /ä¸ªäºº/å‚è€ƒ/ç ”ç©¶/æƒ³æ³•
    "priority": "ä¸­",          # ä¼˜å…ˆçº§: é«˜/ä¸­/ä½
    "summary": "æ–‡æ¡£æ‘˜è¦...",
    "tags": "Python,å­¦ä¹ ,ç¬”è®°", # é€—å·åˆ†éš”çš„æ ‡ç­¾å­—ç¬¦ä¸²
    "confidence": 0.75
}
```

**åˆ†ç±»è§„åˆ™**:
åŸºäºå…³é”®è¯åŒ¹é…è§„åˆ™ï¼Œå‚è§ `document_loader_simple.py` ä¸­çš„ `category_rules`ã€‚

---

## 3. Gradio UIäº‹ä»¶æ¥å£

### 3.1 KnowledgeManagerApp ç±»

#### 3.1.1 load_and_process_files()
**åŠŸèƒ½**: å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶

**æ–¹æ³•ç­¾å**:
```python
def load_and_process_files(self, files: List[str]) -> str
```

**å‚æ•°**:
- `files`: Gradio Fileç»„ä»¶ä¼ é€’çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨

**è¿”å›**:
- `str`: å¤„ç†ç»“æœæ¶ˆæ¯ï¼ˆæ˜¾ç¤ºåœ¨UIä¸Šï¼‰

**UIç»‘å®š**:
```python
upload_btn.click(
    self.load_and_process_files,
    inputs=[file_input],
    outputs=[status_output]
)
```

#### 3.1.2 chat_with_knowledge()
**åŠŸèƒ½**: æ™ºèƒ½é—®ç­”å¯¹è¯

**æ–¹æ³•ç­¾å**:
```python
def chat_with_knowledge(
    self,
    message: str,
    history: List[Dict[str, str]]
) -> str
```

**å‚æ•°**:
- `message`: ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
- `history`: å¯¹è¯å†å²ï¼ˆGradioè‡ªåŠ¨ç®¡ç†ï¼‰

**è¿”å›**:
- `str`: AIå›ç­”ï¼ˆMarkdownæ ¼å¼ï¼‰

**UIç»‘å®š**:
```python
chatbot.submit(
    self.chat_with_knowledge,
    inputs=[msg, chatbot],
    outputs=[chatbot, msg]
)
```

#### 3.1.3 search_knowledge()
**åŠŸèƒ½**: æœç´¢çŸ¥è¯†åº“

**æ–¹æ³•ç­¾å**:
```python
def search_knowledge(
    self,
    query: str,
    mode: str = "æ··åˆæ£€ç´¢",
    top_k: int = 5
) -> str
```

**å‚æ•°**:
| å‚æ•°å | ç±»å‹ | è¯´æ˜ |
|--------|------|------|
| query | str | æœç´¢å…³é”®è¯ |
| mode | str | æ£€ç´¢æ¨¡å¼ï¼ˆæ··åˆæ£€ç´¢/è¯­ä¹‰æ£€ç´¢/å…³é”®è¯æ£€ç´¢ï¼‰ |
| top_k | int | è¿”å›ç»“æœæ•°é‡ |

**è¿”å›**:
- `str`: æ ¼å¼åŒ–çš„æœç´¢ç»“æœï¼ˆMarkdownï¼‰

#### 3.1.4 get_statistics()
**åŠŸèƒ½**: è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯

**æ–¹æ³•ç­¾å**:
```python
def get_statistics(self) -> str
```

**è¿”å›**:
- `str`: æ ¼å¼åŒ–çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆMarkdownï¼‰

**è¿”å›å†…å®¹ç¤ºä¾‹**:
```markdown
ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯

ğŸ“ æ–‡æ¡£ç»Ÿè®¡:
  â€¢ æ€»æ–‡æ¡£æ•°: 15 ä¸ªæ–‡ä»¶
  â€¢ æ€»æ–‡æ¡£å—: 127 ä¸ª

ğŸ“‚ åˆ†ç±»ç»Ÿè®¡:
  â€¢ å­¦ä¹ : 8 ä¸ªæ–‡ä»¶
  â€¢ å·¥ä½œ: 5 ä¸ªæ–‡ä»¶
  â€¢ å‚è€ƒ: 2 ä¸ªæ–‡ä»¶

ğŸ§  Embeddingä¿¡æ¯:
  â€¢ æ–¹æ³•: Sentence Transformers (all-MiniLM-L6-v2)
  â€¢ ç»´åº¦: 384
  â€¢ å…è´¹æ–¹æ¡ˆ: âœ…
```

#### 3.1.5 get_document_list()
**åŠŸèƒ½**: è·å–æ–‡æ¡£åˆ—è¡¨

**æ–¹æ³•ç­¾å**:
```python
def get_document_list(self) -> List[List[str]]
```

**è¿”å›**:
```python
[
    ["python_notes.md", "12", "å­¦ä¹ ", ".md"],
    ["project_plan.pdf", "8", "å·¥ä½œ", ".pdf"],
    # ...
]
```

**UIæ˜¾ç¤º**: åœ¨Gradio Dataframeç»„ä»¶ä¸­å±•ç¤º

#### 3.1.6 delete_document_by_filename()
**åŠŸèƒ½**: åˆ é™¤æŒ‡å®šæ–‡ä»¶

**æ–¹æ³•ç­¾å**:
```python
def delete_document_by_filename(self, filename: str) -> str
```

**å‚æ•°**:
- `filename`: è¦åˆ é™¤çš„æ–‡ä»¶åï¼ˆå®Œæ•´æ–‡ä»¶åï¼‰

**è¿”å›**:
- `str`: åˆ é™¤ç»“æœæ¶ˆæ¯

#### 3.1.7 update_document()
**åŠŸèƒ½**: æ›´æ–°æ–‡æ¡£ï¼ˆåˆ é™¤æ—§ç‰ˆæœ¬+ä¸Šä¼ æ–°ç‰ˆæœ¬ï¼‰

**æ–¹æ³•ç­¾å**:
```python
def update_document(self, old_filename: str, file) -> str
```

**å‚æ•°**:
- `old_filename`: è¦æ›¿æ¢çš„æ—§æ–‡ä»¶å
- `file`: Gradio Fileå¯¹è±¡ï¼ˆæ–°æ–‡ä»¶ï¼‰

**è¿”å›**:
- `str`: æ›´æ–°ç»“æœæ¶ˆæ¯

---

## 4. å¤–éƒ¨APIè°ƒç”¨æ¥å£

### 4.1 OpenAI API

#### 4.1.1 Embeddings API
**ç”¨é€”**: é«˜è´¨é‡æ–‡æœ¬åµŒå…¥ï¼ˆå¯é€‰ï¼‰

**è°ƒç”¨æ–¹å¼**:
```python
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    openai_api_key=settings.OPENAI_API_KEY
)
vectors = embeddings.embed_documents(texts)
```

**é…ç½®**:
- ç¯å¢ƒå˜é‡: `OPENAI_API_KEY`
- æ¨¡å‹: `text-embedding-3-small`
- ç»´åº¦: 1536

---

### 4.2 DeepSeek API

#### 4.2.1 Chat Completions API
**ç”¨é€”**: LLMå¯¹è¯ç”Ÿæˆ

**è°ƒç”¨æ–¹å¼**:
```python
from langchain_deepseek import ChatDeepSeek

chat_model = ChatDeepSeek(
    model="deepseek-chat",
    api_key=settings.DEEPSEEK_API_KEY,
    temperature=0.7,
    max_tokens=500
)
response = chat_model.invoke(messages)
```

**é…ç½®**:
- ç¯å¢ƒå˜é‡: `DEEPSEEK_API_KEY`
- æ¨¡å‹: `deepseek-chat`
- æ¸©åº¦: 0.7
- æœ€å¤§Token: 500

---

## 5. æ•°æ®ç»“æ„å®šä¹‰

### 5.1 LangChainDocument

**LangChainæ ¸å¿ƒæ–‡æ¡£å¯¹è±¡**:
```python
from langchain_core.documents import Document

doc = Document(
    page_content="æ–‡æ¡£æ–‡æœ¬å†…å®¹",
    metadata={
        # æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
        "source": "/absolute/path/to/file.pdf",
        "filename": "file.pdf",
        "file_type": ".pdf",
        "file_size": 2.5,  # MB
        
        # åˆ†å—ä¿¡æ¯
        "chunk_id": 0,
        "total_chunks": 5,
        "content_hash": "hash_value",
        
        # åˆ†ç±»ä¿¡æ¯
        "category": "å­¦ä¹ ",
        "priority": "é«˜",
        "tags": "Python,å­¦ä¹ ",
        "summary": "æ–‡æ¡£æ‘˜è¦...",
        
        # æ£€ç´¢ç›¸å…³ï¼ˆæœç´¢æ—¶æ·»åŠ ï¼‰
        "search_score": 0.85,
        "relevance_score": 0.75,
        "doc_id": "doc_xxx"
    }
)
```

### 5.2 é…ç½®å¯¹è±¡ (Settings)

**å…¨å±€é…ç½®ç±»**:
```python
class Settings:
    # APIå¯†é’¥
    OPENAI_API_KEY: Optional[str]
    DEEPSEEK_API_KEY: Optional[str]
    
    # è·¯å¾„é…ç½®
    VECTOR_DB_PATH: str = "./data/vector_db"
    
    # RAGå‚æ•°
    CHUNK_SIZE: int = 1000
    CHUNK_OVERLAP: int = 200
    TOP_K: int = 5
    MAX_TOKENS: int = 500
    TEMPERATURE: float = 0.7
    
    # Embeddingé…ç½®
    EMBEDDING_MODEL: str = "text-embedding-3-small"
    EMBEDDING_METHOD: str = "auto"
    
    # Gradioé…ç½®
    GRADIO_SERVER_PORT: int = 8888
    GRADIO_SERVER_HOST: str = "127.0.0.1"
    
    # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
    SUPPORTED_FILE_TYPES = [".pdf", ".txt", ".md", ".docx"]
    MAX_FILE_SIZE_MB = 50
    
    # åˆ†ç±»æ ‡ç­¾
    DOCUMENT_CATEGORIES = ["å·¥ä½œ", "å­¦ä¹ ", "ä¸ªäºº", "å‚è€ƒ", "ç ”ç©¶", "æƒ³æ³•"]
    PRIORITY_LEVELS = ["é«˜", "ä¸­", "ä½"]
```

---

## 6. é”™è¯¯ç ä¸å¼‚å¸¸

### 6.1 å¸¸è§å¼‚å¸¸

| å¼‚å¸¸ç±»å‹ | è§¦å‘åœºæ™¯ | å¤„ç†æ–¹å¼ |
|---------|---------|---------|
| `FileNotFoundError` | æ–‡ä»¶ä¸å­˜åœ¨ | æç¤ºç”¨æˆ·æ£€æŸ¥è·¯å¾„ |
| `ValueError` | å‚æ•°æ— æ•ˆï¼ˆæ–‡ä»¶è¿‡å¤§ã€æ ¼å¼ä¸æ”¯æŒï¼‰ | è¿”å›é”™è¯¯ä¿¡æ¯ |
| `ImportError` | ä¾èµ–åº“ç¼ºå¤± | é™çº§åˆ°å¤‡ç”¨æ–¹æ¡ˆ |
| `APIError` | APIè°ƒç”¨å¤±è´¥ | é‡è¯•æˆ–é™çº§ |

### 6.2 é”™è¯¯å¤„ç†ç¤ºä¾‹

```python
try:
    documents = loader.load_file(file_path)
except FileNotFoundError:
    return "âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„"
except ValueError as e:
    return f"âŒ æ–‡ä»¶éªŒè¯å¤±è´¥: {str(e)}"
except Exception as e:
    logger.error(f"æœªçŸ¥é”™è¯¯: {e}")
    return "âŒ å¤„ç†å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—"
```

---

## 7. APIè°ƒç”¨æµç¨‹ç¤ºä¾‹

### 7.1 å®Œæ•´çš„æ–‡æ¡£ä¸Šä¼ æµç¨‹

```python
# 1. ç”¨æˆ·ä¸Šä¼ æ–‡ä»¶ (Gradio UI)
files = ["/path/to/doc1.pdf", "/path/to/doc2.md"]

# 2. è°ƒç”¨å¤„ç†æ–¹æ³•
app = KnowledgeManagerApp()
result = app.load_and_process_files(files)

# å†…éƒ¨æµç¨‹:
# 2.1 DocumentLoader.load_file() - åŠ è½½æ–‡æ¡£
# 2.2 DocumentClassifier.classify_document() - åˆ†ç±»
# 2.3 EmbeddingManager.embed_documents() - ç”Ÿæˆembedding
# 2.4 VectorStore.add_documents() - å­˜å‚¨åˆ°æ•°æ®åº“

# 3. è¿”å›ç»“æœç»™ç”¨æˆ·
print(result)  # "âœ… æˆåŠŸå¤„ç† 15 ä¸ªæ–‡æ¡£å—..."
```

### 7.2 å®Œæ•´çš„æ™ºèƒ½é—®ç­”æµç¨‹

```python
# 1. ç”¨æˆ·æé—®
query = "Pythonè£…é¥°å™¨å¦‚ä½•ä½¿ç”¨?"

# 2. è°ƒç”¨é—®ç­”æ–¹æ³•
app = KnowledgeManagerApp()
answer = app.chat_with_knowledge(query, history=[])

# å†…éƒ¨æµç¨‹:
# 2.1 VectorStore.search() - æ£€ç´¢ç›¸å…³æ–‡æ¡£
# 2.2 RAGGenerator.generate_answer() - ç”Ÿæˆç­”æ¡ˆ
#     2.2.1 æ„å»ºä¸Šä¸‹æ–‡
#     2.2.2 è°ƒç”¨DeepSeek API (å¦‚æœå¯ç”¨)
#     2.2.3 æå–æ¥æºå¼•ç”¨

# 3. è¿”å›æ ¼å¼åŒ–ç­”æ¡ˆ
print(answer)  # Markdownæ ¼å¼çš„ç­”æ¡ˆ
```

---

## 8. æ¥å£è°ƒç”¨æœ€ä½³å®è·µ

### 8.1 æ€§èƒ½ä¼˜åŒ–
```python
# âœ… æ‰¹é‡å¤„ç†
documents = loader.load_multiple_files(file_paths)

# âŒ é¿å…å¾ªç¯å•ä¸ªå¤„ç†
for path in file_paths:
    loader.load_file(path)  # æ•ˆç‡ä½
```

### 8.2 é”™è¯¯å¤„ç†
```python
# âœ… ä¼˜é›…é™çº§
try:
    result = primary_method()
except Exception:
    result = fallback_method()

# âŒ ç›´æ¥å´©æºƒ
result = risky_method()  # å¯èƒ½æŠ›å¼‚å¸¸
```

### 8.3 èµ„æºç®¡ç†
```python
# âœ… é™åˆ¶è¿”å›æ•°é‡
results = vector_store.search(query, k=5)

# âŒ æ— é™åˆ¶è¿”å›
results = vector_store.search(query, k=1000)  # å¯èƒ½OOM
```

---

## 9. æ¥å£ç‰ˆæœ¬ç®¡ç†

å½“å‰ç‰ˆæœ¬: **v1.0.0**

### 9.1 å…¼å®¹æ€§ä¿è¯
- ä¸»ç‰ˆæœ¬å·å˜æ›´ï¼šä¸å…¼å®¹çš„APIå˜æ›´
- æ¬¡ç‰ˆæœ¬å·å˜æ›´ï¼šå‘åå…¼å®¹çš„åŠŸèƒ½æ–°å¢
- ä¿®è®¢å·å˜æ›´ï¼šå‘åå…¼å®¹çš„é—®é¢˜ä¿®å¤

### 9.2 åºŸå¼ƒç­–ç•¥
- æ ‡è®°ä¸º `@deprecated` å¹¶åœ¨æ—¥å¿—ä¸­è­¦å‘Š
- è‡³å°‘ä¿ç•™ä¸€ä¸ªå¤§ç‰ˆæœ¬å‘¨æœŸ
- æä¾›è¿ç§»æŒ‡å—

---

## 10. å‚è€ƒèµ„æ–™

- [LangChain Document API](https://python.langchain.com/docs/modules/data_connection/document_loaders/)
- [ChromaDB Python Client](https://docs.trychroma.com/reference/python-client)
- [Gradio Event Listeners](https://www.gradio.app/docs/chatinterface)

---

**æ–‡æ¡£ç»´æŠ¤**: æ¥å£å˜æ›´æ—¶è¯·åŠæ—¶æ›´æ–°æœ¬æ–‡æ¡£
